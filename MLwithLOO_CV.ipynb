{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "czOpSYtHXsmr",
        "Hd3LYesNXolS",
        "b_zxi3imc1pu",
        "Z_4de0m5sZp-",
        "IBIUot2Vsf9D",
        "7IDcKSlf0MUZ",
        "OBDb2Ubx_FiQ",
        "4zir3sUM_2W5",
        "zA_PFDJnGnrH",
        "15XXh2sJGv3s",
        "OV7FvV2zGzo-",
        "PeNHMUEQncIa",
        "g110jeBzTtRz",
        "lJD4d2FnG3G-",
        "R6mA6S6UG3pP",
        "BLwrb35HG5kG",
        "bbRQDssWK39X"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "■ The progam for conducting Leave-One-Out Cross Validation using seven ML models with newMaxGD2.csv file on Google Colaboratory. "
      ],
      "metadata": {
        "id": "sfGbQ_JPaL2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "◇ This program is written for use on Google Cobaboratory."
      ],
      "metadata": {
        "id": "wXlot4nya7BU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDuRoU5GXU0p"
      },
      "source": [
        "#1 Environment Setting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czOpSYtHXsmr"
      },
      "source": [
        "## 1) Mount this file on Google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9OWkXJ4XOSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab02780b-1334-4f58-e533-a4b2b7264e37"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hd3LYesNXolS"
      },
      "source": [
        "## 2) Data preparation : [Important]  Change the pass for a dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBi4lQ5TXZX9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3048838e-c34a-416e-f503-8a758cf4a1fd"
      },
      "source": [
        "# Loading modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "# Change the pass: 'drive/My Drive/program/data/renaldata.clsv' to a new pass where newMaxGD2.csv is located in your enviromnent \n",
        "df = pd.read_csv('drive/My Drive/program/data/newMaxGD2.csv')\n",
        "print('Number of colums and rows')\n",
        "print(df.shape)\n",
        "print()\n",
        "print('Number of empty cells')\n",
        "pd.set_option('display.max_rows', 1000)\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of colums and rows\n",
            "(43, 61)\n",
            "\n",
            "Number of empty cells\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "blank・forRBx・M                                      0\n",
              "pMen                                                0\n",
              "age・DATEDIF                                         0\n",
              "localization3・RenalCortex・1innner・2middle・3outer    0\n",
              "arteriolosclerosisG03                               0\n",
              "intimaThickened・G03                                 0\n",
              "interstitial・Inflammation・Percent                   0\n",
              "interstitial・fibrosis・Percent                       0\n",
              "nGlomuruli                                          0\n",
              "rGS・Percent                                         0\n",
              "rFGS・Percent                                        0\n",
              "rOxfordS1                                           0\n",
              "rOxfordM1                                           0\n",
              "nMesCells・perLesion                                 0\n",
              "rMesG03                                             0\n",
              "rOxfordE1                                           0\n",
              "rCrescent・Percent・C                                 0\n",
              "rCrescent・Percent・F                                 0\n",
              "rOxfordC2                                           0\n",
              "rCrescent・Percent・C・FC・F                            0\n",
              "pAdhesion                                           1\n",
              "pThichness・Membane                                  1\n",
              "pPerihylar・Lesion                                   1\n",
              "protein・Iintake・perKg・IBW                           0\n",
              "pNephroticS                                         0\n",
              "pEdema                                              0\n",
              "ｃBMI                                                0\n",
              "cSBP                                                0\n",
              "cDBP                                                0\n",
              "cPP                                                 0\n",
              "cMBP                                                0\n",
              "wbc                                                 1\n",
              "hb                                                  1\n",
              "plt                                                 1\n",
              "tp                                                  0\n",
              "alb                                                 0\n",
              "eGFR・Baseline                                       0\n",
              "pAKI                                                0\n",
              "crp                                                 1\n",
              "igG                                                 0\n",
              "igA                                                 0\n",
              "igM                                                 0\n",
              "c3c                                                 1\n",
              "c4                                                  1\n",
              "cUP・gday・forAnalyses                                0\n",
              "salt・gday                                           0\n",
              "uRBC・counts                                         2\n",
              "uWBC・counts                                         2\n",
              "pHTN・Drug・14090                                     0\n",
              "pHC・Drug・TC220                                      0\n",
              "pTG・Drug・TG150                                      0\n",
              "pHU・Drug・UA７                                        0\n",
              "pFamilyH                                            0\n",
              "cHeight・ｍ                                           0\n",
              "cBW・ｋｇ                                              0\n",
              "cProgGrade4・Japan                                   0\n",
              "cHematuria・qual・Mean10y20p                          0\n",
              "pIncrease・Hematuria・qual・10y                        0\n",
              "cUP・qual・Mean10y20p                                 0\n",
              "increaseUP・qual・10y                                 0\n",
              "pMaxGD242                                           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Xu8HzxaE4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ba97365-0a4b-4549-b8b1-2850c2aa49ec"
      },
      "source": [
        "# Interpolation of missing data   　df2: pandas data、    data: numpy data\n",
        "df2 = df.fillna(df.median())\n",
        "data = df2.values\n",
        "\n",
        "df2.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "blank・forRBx・M                                      0\n",
              "pMen                                                0\n",
              "age・DATEDIF                                         0\n",
              "localization3・RenalCortex・1innner・2middle・3outer    0\n",
              "arteriolosclerosisG03                               0\n",
              "intimaThickened・G03                                 0\n",
              "interstitial・Inflammation・Percent                   0\n",
              "interstitial・fibrosis・Percent                       0\n",
              "nGlomuruli                                          0\n",
              "rGS・Percent                                         0\n",
              "rFGS・Percent                                        0\n",
              "rOxfordS1                                           0\n",
              "rOxfordM1                                           0\n",
              "nMesCells・perLesion                                 0\n",
              "rMesG03                                             0\n",
              "rOxfordE1                                           0\n",
              "rCrescent・Percent・C                                 0\n",
              "rCrescent・Percent・F                                 0\n",
              "rOxfordC2                                           0\n",
              "rCrescent・Percent・C・FC・F                            0\n",
              "pAdhesion                                           0\n",
              "pThichness・Membane                                  0\n",
              "pPerihylar・Lesion                                   0\n",
              "protein・Iintake・perKg・IBW                           0\n",
              "pNephroticS                                         0\n",
              "pEdema                                              0\n",
              "ｃBMI                                                0\n",
              "cSBP                                                0\n",
              "cDBP                                                0\n",
              "cPP                                                 0\n",
              "cMBP                                                0\n",
              "wbc                                                 0\n",
              "hb                                                  0\n",
              "plt                                                 0\n",
              "tp                                                  0\n",
              "alb                                                 0\n",
              "eGFR・Baseline                                       0\n",
              "pAKI                                                0\n",
              "crp                                                 0\n",
              "igG                                                 0\n",
              "igA                                                 0\n",
              "igM                                                 0\n",
              "c3c                                                 0\n",
              "c4                                                  0\n",
              "cUP・gday・forAnalyses                                0\n",
              "salt・gday                                           0\n",
              "uRBC・counts                                         0\n",
              "uWBC・counts                                         0\n",
              "pHTN・Drug・14090                                     0\n",
              "pHC・Drug・TC220                                      0\n",
              "pTG・Drug・TG150                                      0\n",
              "pHU・Drug・UA７                                        0\n",
              "pFamilyH                                            0\n",
              "cHeight・ｍ                                           0\n",
              "cBW・ｋｇ                                              0\n",
              "cProgGrade4・Japan                                   0\n",
              "cHematuria・qual・Mean10y20p                          0\n",
              "pIncrease・Hematuria・qual・10y                        0\n",
              "cUP・qual・Mean10y20p                                 0\n",
              "increaseUP・qual・10y                                 0\n",
              "pMaxGD242                                           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uLtuvrgN00S"
      },
      "source": [
        "# Dividing explanatory variables and target variable\n",
        "x = df2.iloc[:, :-1].values\n",
        "t = df2.iloc[:, -1].values\n",
        "\n",
        "# splitting the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, t_train, t_test = train_test_split(x, t, test_size=0.3, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oloSPaZ1cD5Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "5a40ca17-7f18-44d0-ce73-386b9a5fff67"
      },
      "source": [
        "# Size of dataset\n",
        "print('Number of columns and rows')\n",
        "print(df2.shape)\n",
        "print()\n",
        "print(data)\n",
        "df2.head()\n",
        "# Distribution of target\n",
        "print()\n",
        "print('Distribution of target value')\n",
        "sns.distplot(df2.iloc[:,-1].dropna())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of columns and rows\n",
            "(43, 61)\n",
            "\n",
            "[[  7.     1.    26.   ...   0.63   0.     1.  ]\n",
            " [ 51.     1.    41.   ...   1.6    1.     0.  ]\n",
            " [257.     1.    44.   ...   1.5    1.     1.  ]\n",
            " ...\n",
            " [100.     1.    42.   ...   1.63   0.     0.  ]\n",
            " [ 15.     1.    43.   ...   1.13   1.     0.  ]\n",
            " [ 17.     1.    51.   ...   0.28   0.     0.  ]]\n",
            "\n",
            "Distribution of target value\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc83e7cbe80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1pckzWuuOA4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "129a7f16-0d3f-45bd-8a64-02eb60326cde"
      },
      "source": [
        "df2.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 43 entries, 0 to 42\n",
            "Data columns (total 61 columns):\n",
            " #   Column                                            Non-Null Count  Dtype  \n",
            "---  ------                                            --------------  -----  \n",
            " 0   blank・forRBx・M                                    43 non-null     int64  \n",
            " 1   pMen                                              43 non-null     int64  \n",
            " 2   age・DATEDIF                                       43 non-null     int64  \n",
            " 3   localization3・RenalCortex・1innner・2middle・3outer  43 non-null     int64  \n",
            " 4   arteriolosclerosisG03                             43 non-null     int64  \n",
            " 5   intimaThickened・G03                               43 non-null     int64  \n",
            " 6   interstitial・Inflammation・Percent                 43 non-null     int64  \n",
            " 7   interstitial・fibrosis・Percent                     43 non-null     int64  \n",
            " 8   nGlomuruli                                        43 non-null     int64  \n",
            " 9   rGS・Percent                                       43 non-null     float64\n",
            " 10  rFGS・Percent                                      43 non-null     float64\n",
            " 11  rOxfordS1                                         43 non-null     int64  \n",
            " 12  rOxfordM1                                         43 non-null     int64  \n",
            " 13  nMesCells・perLesion                               43 non-null     int64  \n",
            " 14  rMesG03                                           43 non-null     int64  \n",
            " 15  rOxfordE1                                         43 non-null     int64  \n",
            " 16  rCrescent・Percent・C                               43 non-null     float64\n",
            " 17  rCrescent・Percent・F                               43 non-null     float64\n",
            " 18  rOxfordC2                                         43 non-null     int64  \n",
            " 19  rCrescent・Percent・C・FC・F                          43 non-null     float64\n",
            " 20  pAdhesion                                         43 non-null     float64\n",
            " 21  pThichness・Membane                                43 non-null     float64\n",
            " 22  pPerihylar・Lesion                                 43 non-null     float64\n",
            " 23  protein・Iintake・perKg・IBW                         43 non-null     float64\n",
            " 24  pNephroticS                                       43 non-null     int64  \n",
            " 25  pEdema                                            43 non-null     int64  \n",
            " 26  ｃBMI                                              43 non-null     float64\n",
            " 27  cSBP                                              43 non-null     int64  \n",
            " 28  cDBP                                              43 non-null     int64  \n",
            " 29  cPP                                               43 non-null     int64  \n",
            " 30  cMBP                                              43 non-null     float64\n",
            " 31  wbc                                               43 non-null     float64\n",
            " 32  hb                                                43 non-null     float64\n",
            " 33  plt                                               43 non-null     float64\n",
            " 34  tp                                                43 non-null     float64\n",
            " 35  alb                                               43 non-null     float64\n",
            " 36  eGFR・Baseline                                     43 non-null     float64\n",
            " 37  pAKI                                              43 non-null     int64  \n",
            " 38  crp                                               43 non-null     float64\n",
            " 39  igG                                               43 non-null     int64  \n",
            " 40  igA                                               43 non-null     int64  \n",
            " 41  igM                                               43 non-null     int64  \n",
            " 42  c3c                                               43 non-null     float64\n",
            " 43  c4                                                43 non-null     float64\n",
            " 44  cUP・gday・forAnalyses                              43 non-null     float64\n",
            " 45  salt・gday                                         43 non-null     float64\n",
            " 46  uRBC・counts                                       43 non-null     float64\n",
            " 47  uWBC・counts                                       43 non-null     float64\n",
            " 48  pHTN・Drug・14090                                   43 non-null     int64  \n",
            " 49  pHC・Drug・TC220                                    43 non-null     int64  \n",
            " 50  pTG・Drug・TG150                                    43 non-null     int64  \n",
            " 51  pHU・Drug・UA７                                      43 non-null     int64  \n",
            " 52  pFamilyH                                          43 non-null     int64  \n",
            " 53  cHeight・ｍ                                         43 non-null     float64\n",
            " 54  cBW・ｋｇ                                            43 non-null     float64\n",
            " 55  cProgGrade4・Japan                                 43 non-null     int64  \n",
            " 56  cHematuria・qual・Mean10y20p                        43 non-null     float64\n",
            " 57  pIncrease・Hematuria・qual・10y                      43 non-null     int64  \n",
            " 58  cUP・qual・Mean10y20p                               43 non-null     float64\n",
            " 59  increaseUP・qual・10y                               43 non-null     int64  \n",
            " 60  pMaxGD242                                         43 non-null     int64  \n",
            "dtypes: float64(28), int64(33)\n",
            "memory usage: 20.6 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooASPGa_ubSL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "2754fa9c-5d73-4c0a-e776-3d7ab3c44eb2"
      },
      "source": [
        "df2.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>blank・forRBx・M</th>\n",
              "      <th>pMen</th>\n",
              "      <th>age・DATEDIF</th>\n",
              "      <th>localization3・RenalCortex・1innner・2middle・3outer</th>\n",
              "      <th>arteriolosclerosisG03</th>\n",
              "      <th>intimaThickened・G03</th>\n",
              "      <th>interstitial・Inflammation・Percent</th>\n",
              "      <th>interstitial・fibrosis・Percent</th>\n",
              "      <th>nGlomuruli</th>\n",
              "      <th>rGS・Percent</th>\n",
              "      <th>rFGS・Percent</th>\n",
              "      <th>rOxfordS1</th>\n",
              "      <th>rOxfordM1</th>\n",
              "      <th>nMesCells・perLesion</th>\n",
              "      <th>rMesG03</th>\n",
              "      <th>rOxfordE1</th>\n",
              "      <th>rCrescent・Percent・C</th>\n",
              "      <th>rCrescent・Percent・F</th>\n",
              "      <th>rOxfordC2</th>\n",
              "      <th>rCrescent・Percent・C・FC・F</th>\n",
              "      <th>pAdhesion</th>\n",
              "      <th>pThichness・Membane</th>\n",
              "      <th>pPerihylar・Lesion</th>\n",
              "      <th>protein・Iintake・perKg・IBW</th>\n",
              "      <th>pNephroticS</th>\n",
              "      <th>pEdema</th>\n",
              "      <th>ｃBMI</th>\n",
              "      <th>cSBP</th>\n",
              "      <th>cDBP</th>\n",
              "      <th>cPP</th>\n",
              "      <th>cMBP</th>\n",
              "      <th>wbc</th>\n",
              "      <th>hb</th>\n",
              "      <th>plt</th>\n",
              "      <th>tp</th>\n",
              "      <th>alb</th>\n",
              "      <th>eGFR・Baseline</th>\n",
              "      <th>pAKI</th>\n",
              "      <th>crp</th>\n",
              "      <th>igG</th>\n",
              "      <th>igA</th>\n",
              "      <th>igM</th>\n",
              "      <th>c3c</th>\n",
              "      <th>c4</th>\n",
              "      <th>cUP・gday・forAnalyses</th>\n",
              "      <th>salt・gday</th>\n",
              "      <th>uRBC・counts</th>\n",
              "      <th>uWBC・counts</th>\n",
              "      <th>pHTN・Drug・14090</th>\n",
              "      <th>pHC・Drug・TC220</th>\n",
              "      <th>pTG・Drug・TG150</th>\n",
              "      <th>pHU・Drug・UA７</th>\n",
              "      <th>pFamilyH</th>\n",
              "      <th>cHeight・ｍ</th>\n",
              "      <th>cBW・ｋｇ</th>\n",
              "      <th>cProgGrade4・Japan</th>\n",
              "      <th>cHematuria・qual・Mean10y20p</th>\n",
              "      <th>pIncrease・Hematuria・qual・10y</th>\n",
              "      <th>cUP・qual・Mean10y20p</th>\n",
              "      <th>increaseUP・qual・10y</th>\n",
              "      <th>pMaxGD242</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.00000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.00000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>43.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>80.093023</td>\n",
              "      <td>0.604651</td>\n",
              "      <td>39.325581</td>\n",
              "      <td>1.976744</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>7.790698</td>\n",
              "      <td>11.116279</td>\n",
              "      <td>13.395349</td>\n",
              "      <td>17.381395</td>\n",
              "      <td>16.041860</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>6.813953</td>\n",
              "      <td>2.255814</td>\n",
              "      <td>0.534884</td>\n",
              "      <td>9.390698</td>\n",
              "      <td>1.230233</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>10.618605</td>\n",
              "      <td>0.093023</td>\n",
              "      <td>0.093023</td>\n",
              "      <td>0.418605</td>\n",
              "      <td>1.051395</td>\n",
              "      <td>0.139535</td>\n",
              "      <td>0.139535</td>\n",
              "      <td>25.362791</td>\n",
              "      <td>143.116279</td>\n",
              "      <td>82.348837</td>\n",
              "      <td>60.767442</td>\n",
              "      <td>102.620930</td>\n",
              "      <td>67.813953</td>\n",
              "      <td>14.187209</td>\n",
              "      <td>21.55814</td>\n",
              "      <td>6.481395</td>\n",
              "      <td>3.788372</td>\n",
              "      <td>78.555814</td>\n",
              "      <td>0.116279</td>\n",
              "      <td>0.142209</td>\n",
              "      <td>1141.767442</td>\n",
              "      <td>337.162791</td>\n",
              "      <td>166.023256</td>\n",
              "      <td>90.372093</td>\n",
              "      <td>36.895349</td>\n",
              "      <td>1.794186</td>\n",
              "      <td>8.566977</td>\n",
              "      <td>38.604651</td>\n",
              "      <td>5.488372</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.232558</td>\n",
              "      <td>0.372093</td>\n",
              "      <td>0.27907</td>\n",
              "      <td>0.139535</td>\n",
              "      <td>1.633953</td>\n",
              "      <td>68.167442</td>\n",
              "      <td>2.906977</td>\n",
              "      <td>1.418605</td>\n",
              "      <td>0.395349</td>\n",
              "      <td>1.279767</td>\n",
              "      <td>0.372093</td>\n",
              "      <td>0.348837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>88.920996</td>\n",
              "      <td>0.494712</td>\n",
              "      <td>9.738781</td>\n",
              "      <td>0.672181</td>\n",
              "      <td>0.786796</td>\n",
              "      <td>0.747087</td>\n",
              "      <td>8.331118</td>\n",
              "      <td>10.823716</td>\n",
              "      <td>5.508174</td>\n",
              "      <td>16.073007</td>\n",
              "      <td>15.497976</td>\n",
              "      <td>0.393750</td>\n",
              "      <td>0.393750</td>\n",
              "      <td>1.531507</td>\n",
              "      <td>0.789606</td>\n",
              "      <td>0.504685</td>\n",
              "      <td>14.435931</td>\n",
              "      <td>3.226124</td>\n",
              "      <td>0.650411</td>\n",
              "      <td>15.138382</td>\n",
              "      <td>0.293903</td>\n",
              "      <td>0.293903</td>\n",
              "      <td>0.499169</td>\n",
              "      <td>0.258923</td>\n",
              "      <td>0.350605</td>\n",
              "      <td>0.350605</td>\n",
              "      <td>4.328753</td>\n",
              "      <td>22.203828</td>\n",
              "      <td>15.425526</td>\n",
              "      <td>13.410794</td>\n",
              "      <td>16.824593</td>\n",
              "      <td>12.791842</td>\n",
              "      <td>2.038063</td>\n",
              "      <td>6.07290</td>\n",
              "      <td>0.586457</td>\n",
              "      <td>0.391097</td>\n",
              "      <td>17.545591</td>\n",
              "      <td>0.324353</td>\n",
              "      <td>0.187922</td>\n",
              "      <td>320.971801</td>\n",
              "      <td>139.702734</td>\n",
              "      <td>92.016429</td>\n",
              "      <td>18.976205</td>\n",
              "      <td>10.728000</td>\n",
              "      <td>1.491610</td>\n",
              "      <td>3.054627</td>\n",
              "      <td>53.487043</td>\n",
              "      <td>15.417016</td>\n",
              "      <td>0.427463</td>\n",
              "      <td>0.427463</td>\n",
              "      <td>0.489083</td>\n",
              "      <td>0.45385</td>\n",
              "      <td>0.350605</td>\n",
              "      <td>0.082437</td>\n",
              "      <td>15.310139</td>\n",
              "      <td>0.526170</td>\n",
              "      <td>0.757268</td>\n",
              "      <td>0.494712</td>\n",
              "      <td>0.827606</td>\n",
              "      <td>0.489083</td>\n",
              "      <td>0.482243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.540000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.800000</td>\n",
              "      <td>96.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>9.800000</td>\n",
              "      <td>12.40000</td>\n",
              "      <td>5.300000</td>\n",
              "      <td>2.900000</td>\n",
              "      <td>50.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010000</td>\n",
              "      <td>698.000000</td>\n",
              "      <td>118.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.490000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.470000</td>\n",
              "      <td>41.600000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.170000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>16.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>4.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.915000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>22.900000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>73.500000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>92.850000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>12.550000</td>\n",
              "      <td>16.50000</td>\n",
              "      <td>6.150000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>66.350000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.045000</td>\n",
              "      <td>911.000000</td>\n",
              "      <td>223.000000</td>\n",
              "      <td>100.500000</td>\n",
              "      <td>81.500000</td>\n",
              "      <td>31.000000</td>\n",
              "      <td>0.790000</td>\n",
              "      <td>6.455000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.565000</td>\n",
              "      <td>56.550000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.575000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>42.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>14.300000</td>\n",
              "      <td>14.700000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.010000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>25.100000</td>\n",
              "      <td>143.000000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>14.650000</td>\n",
              "      <td>20.70000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>3.800000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.075000</td>\n",
              "      <td>1169.000000</td>\n",
              "      <td>323.000000</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>88.000000</td>\n",
              "      <td>34.500000</td>\n",
              "      <td>1.360000</td>\n",
              "      <td>8.720000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.630000</td>\n",
              "      <td>67.800000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.130000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>100.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>46.500000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>23.100000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>14.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>14.300000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.550000</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>90.000000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>77.500000</td>\n",
              "      <td>15.650000</td>\n",
              "      <td>25.65000</td>\n",
              "      <td>6.850000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>89.450000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.140000</td>\n",
              "      <td>1305.000000</td>\n",
              "      <td>428.500000</td>\n",
              "      <td>208.500000</td>\n",
              "      <td>99.500000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>2.365000</td>\n",
              "      <td>11.020000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.700000</td>\n",
              "      <td>74.350000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.705000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>325.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>34.000000</td>\n",
              "      <td>57.100000</td>\n",
              "      <td>69.200000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>83.300000</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>83.300000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.580000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>37.500000</td>\n",
              "      <td>186.000000</td>\n",
              "      <td>124.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>144.700000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>37.80000</td>\n",
              "      <td>7.700000</td>\n",
              "      <td>4.600000</td>\n",
              "      <td>123.300000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.920000</td>\n",
              "      <td>2412.000000</td>\n",
              "      <td>792.000000</td>\n",
              "      <td>475.000000</td>\n",
              "      <td>149.000000</td>\n",
              "      <td>63.000000</td>\n",
              "      <td>7.040000</td>\n",
              "      <td>13.930000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.790000</td>\n",
              "      <td>114.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.350000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       blank・forRBx・M       pMen  ...  increaseUP・qual・10y  pMaxGD242\n",
              "count       43.000000  43.000000  ...            43.000000  43.000000\n",
              "mean        80.093023   0.604651  ...             0.372093   0.348837\n",
              "std         88.920996   0.494712  ...             0.489083   0.482243\n",
              "min          1.000000   0.000000  ...             0.000000   0.000000\n",
              "25%         16.000000   0.000000  ...             0.000000   0.000000\n",
              "50%         42.000000   1.000000  ...             0.000000   0.000000\n",
              "75%        100.500000   1.000000  ...             1.000000   1.000000\n",
              "max        325.000000   1.000000  ...             1.000000   1.000000\n",
              "\n",
              "[8 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_zxi3imc1pu"
      },
      "source": [
        "## 3) Installation of Optuna and XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BU82o_cBc404",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da106087-e72b-4e6e-dcf3-c97449c8f848"
      },
      "source": [
        "# Installation of Optuna\n",
        "!pip install optuna"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/10/06b58f4120f26b603d905a594650440ea1fd74476b8b360dbf01e111469b/optuna-2.3.0.tar.gz (258kB)\n",
            "\r\u001b[K     |█▎                              | 10kB 19.0MB/s eta 0:00:01\r\u001b[K     |██▌                             | 20kB 13.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 30kB 13.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 40kB 12.3MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 51kB 8.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 61kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 71kB 8.9MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 81kB 9.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 92kB 9.1MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 102kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 112kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 122kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 133kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 143kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 153kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 163kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 174kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 184kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 194kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 204kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 215kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 225kB 7.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 235kB 7.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 245kB 7.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 256kB 7.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 266kB 7.8MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna) (4.41.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (20.4)\n",
            "Collecting cmaes>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/3c/06c76ec8b54b9b1fad7f35e903fd25010fe3e0d41bd94cea5e6f12e0d651/cmaes-0.7.0-py3-none-any.whl\n",
            "Collecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/c8/c16d30bbed11a1722060014c246d124582d1f781b26f5859d8dacc3e08e1/colorlog-4.6.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.20)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna) (0.17.0)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.1)\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/61/5b64d73b01c1218f55c894b5ec0fb89b32c6960b7f7b3ad9f5ac0c373b9d/cliff-3.5.0-py3-none-any.whl (81kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 7.8MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/aa/c261dfd7f4ba6ce4701846a2689a46e2a172e012171de4378fc2926e3bf0/alembic-1.4.3-py2.py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 13.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.18.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging>=20.0->optuna) (1.15.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n",
            "\u001b[?25hCollecting PrettyTable<0.8,>=0.7.2\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/30/4b0746848746ed5941f052479e7c23d2b56d174b82f4fd34a25e389831f5/prettytable-0.7.2.tar.bz2\n",
            "Collecting cmd2!=0.8.3,>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/54/af6e2703f064485d717cb311d3f9440cd302a823ba6d80a020b59eae166d/cmd2-1.4.0-py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 15.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.13)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 17.0MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Collecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/37/0e706200d22172eb8fa17d68a7ae22dec7631a0a92266634fb518a88a5b2/Mako-1.1.3-py2.py3-none-any.whl (75kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Requirement already satisfied: importlib-metadata>=1.7.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from stevedore>=2.0.1->cliff->optuna) (2.0.0)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (20.3.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from cmd2!=0.8.3,>=0.8.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/4c/0b1d507ad7e8bc31d690d04b4f475e74c2002d060f7994ce8c09612df707/pyperclip-1.8.1.tar.gz\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.7.0; python_version < \"3.8\"->stevedore>=2.0.1->cliff->optuna) (3.4.0)\n",
            "Building wheels for collected packages: optuna\n",
            "  Building wheel for optuna (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optuna: filename=optuna-2.3.0-cp36-none-any.whl size=359761 sha256=e339b041b194e549ddc18edb4d9ed779f560c2e2cfe3932c16aaaae062e967f3\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/91/19/64b0ec6b964f89c0695a9dc6db6f851d0b54c5381a5c9cadfb\n",
            "Successfully built optuna\n",
            "Building wheels for collected packages: PrettyTable, pyperclip\n",
            "  Building wheel for PrettyTable (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PrettyTable: filename=prettytable-0.7.2-cp36-none-any.whl size=13700 sha256=6da83be76e00f1090951fd342854c098355ddbb6ad043b78c24d6300c97076e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/34/1c/3967380d9676d162cb59513bd9dc862d0584e045a162095606\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.1-cp36-none-any.whl size=11119 sha256=1a4f5a3f85c2a20be99c23619e516892c830b45a5a60c836170a8b7ea0d6b82a\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/10/3a/c830e9bb3db2c93274ea1f213a41fabde0d8cf3794251fad0c\n",
            "Successfully built PrettyTable pyperclip\n",
            "Installing collected packages: cmaes, colorlog, pbr, stevedore, PrettyTable, colorama, pyperclip, cmd2, cliff, python-editor, Mako, alembic, optuna\n",
            "  Found existing installation: prettytable 2.0.0\n",
            "    Uninstalling prettytable-2.0.0:\n",
            "      Successfully uninstalled prettytable-2.0.0\n",
            "Successfully installed Mako-1.1.3 PrettyTable-0.7.2 alembic-1.4.3 cliff-3.5.0 cmaes-0.7.0 cmd2-1.4.0 colorama-0.4.4 colorlog-4.6.2 optuna-2.3.0 pbr-5.5.1 pyperclip-1.8.1 python-editor-1.0.4 stevedore-3.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKE8Uk1wh6wN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0cc46f5-1206-4992-8840-4ebd9d6bfe7c"
      },
      "source": [
        "# Installation of XGBoost\n",
        "!pip3 install xgboost\n",
        "!pip3 install -q pydot\n",
        "!pip3 install graphviz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (0.10.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbzmUjC4hJKs"
      },
      "source": [
        "# 2. Leave-One-Out cross validation with machine learning models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_4de0m5sZp-"
      },
      "source": [
        "## 1) Simple Linear Regression ; ACU 0.536"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N-TObivfV6A"
      },
      "source": [
        "def linear():\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score\n",
        "\n",
        "    # Rounding of fractional point\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p\n",
        "\n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "    round = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    lr = LinearRegression()\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        lr.fit(x_train, t_train)\n",
        "        result = lr.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "        # Category of prediction\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "\n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/program/data/cstatdata.csv', index=False)\n",
        "\n",
        "    # Coefficient of Determination\n",
        "    r2 = r2_score(t, pred)\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat =  [[TP, FP], [FN, TN]]\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "    \n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, [[TP, FP], [FN, TN]], r2])\n",
        "\n",
        "    # Output　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. Confusion Matrix, 8. R^2 in LOO)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation with Simple Linear Regression')\n",
        "    print('')\n",
        "    print('Sample size of all dataset: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('Sample size of training data: ' + str(len(x_train)) + '     Explanatory variables: ' + str(x_train.shape) + '   Target value: ' + str(t_train.shape))\n",
        "    print('Sample size of test data: ' + str(len(x_test)) + '     Explanatory variables: ' + str(x_test.shape) + '   Target value: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO')\n",
        "    print('')\n",
        "\n",
        "\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WOb2F25lDSr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76db3b9b-d5e7-401e-b0d4-436601bdbf16"
      },
      "source": [
        "linear()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Simple Linear Regression\n",
            "\n",
            "Sample size of all dataset: 43\n",
            "Sample size of training data: 42     Explanatory variables: (42, 60)   Target value: (42,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 60)   Target value: (1,)\n",
            "\n",
            "AUC: 0.53571   Accuracy: 0.48837   R2: -10.82822\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             7            14\n",
            "Predict False            8            14\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5357142857142857, 0.4883720930232558, 0.3333333333333333,\n",
              "       0.4666666666666667, 0.3888888888888889, 0.5,\n",
              "       list([[7, 14], [8, 14]]), -10.828219208996728], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBIUot2Vsf9D"
      },
      "source": [
        "## 2) Lasso Regression ; AUC 0.705"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UObd6dfFlEkH"
      },
      "source": [
        "def lasso(a):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.linear_model import Lasso\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score\n",
        "\n",
        "    # Rounding of fractional point\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p\n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "    round = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    lr = Lasso(alpha=a)\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        lr.fit(x_train, t_train)\n",
        "        result = lr.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "        \t# Category of prediction\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "\n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/program/data/cstatdata.csv', index=False)\n",
        "\n",
        "    # Coefficient of Determination\n",
        "    r2 = r2_score(t, pred)\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat = [[TP, FP], [FN, TN]]\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, confmat, r2])\n",
        "\n",
        "    # Output　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. Confusion Matrix, 8. R^2 in LOO)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation with Lasso Regression')\n",
        "    print('')\n",
        "    print('Sample size of all dataset: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('Sample size of training data: ' + str(len(x_train)) + '     Explanatory variables: ' + str(x_train.shape) + '   Target value: ' + str(t_train.shape))\n",
        "    print('Sample size of test data: ' + str(len(x_test)) + '     Explanatory variables: ' + str(x_test.shape) + '   Target value: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO')\n",
        "    print('')\n",
        "\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IDcKSlf0MUZ"
      },
      "source": [
        "### Optimization with Optuna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHiZDlIM0V5x"
      },
      "source": [
        "def lassoOptuna(trial):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.linear_model import Lasso\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    import optuna\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "\n",
        "    alpha = trial.suggest_uniform('alpha', 0.01, 1)\n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Rounding of fractional point\n",
        "    pred = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    lr = Lasso(alpha=alpha)\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        lr.fit(x_train, t_train)\n",
        "        result = lr.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "     \n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    res = auc\n",
        "    # minimize 1 - AUC\n",
        "    return 1/res\n",
        "\n",
        "\n",
        "def lassoTrial(n_trials):\n",
        "    import optuna\n",
        "    study = optuna.create_study()\n",
        "    study.optimize(lassoOptuna, n_trials)\n",
        "    # result\n",
        "    print()\n",
        "    print('hyper parameter：', study.best_params)\n",
        "    print('AUC：', 1/study.best_value)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlpRWImh1x1R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a57d7a24-593e-42b2-9698-b837f01f4df5"
      },
      "source": [
        "lassoTrial(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-04 09:48:30,944]\u001b[0m A new study created in memory with name: no-name-c718a64f-7628-4548-bc63-42887cb66a43\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:30,982]\u001b[0m Trial 0 finished with value: 1.5613382899628254 and parameters: {'alpha': 0.12810870669011917}. Best is trial 0 with value: 1.5613382899628254.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,009]\u001b[0m Trial 1 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.9035355695351138}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,040]\u001b[0m Trial 2 finished with value: 1.5730337078651684 and parameters: {'alpha': 0.26227895911926136}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,072]\u001b[0m Trial 3 finished with value: 1.5730337078651686 and parameters: {'alpha': 0.1892693051665407}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,101]\u001b[0m Trial 4 finished with value: 1.5498154981549814 and parameters: {'alpha': 0.32854940255398885}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,136]\u001b[0m Trial 5 finished with value: 1.5555555555555558 and parameters: {'alpha': 0.12226832512962563}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,165]\u001b[0m Trial 6 finished with value: 1.4285714285714284 and parameters: {'alpha': 0.8413422802429722}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,193]\u001b[0m Trial 7 finished with value: 1.4285714285714284 and parameters: {'alpha': 0.6978268332583693}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,224]\u001b[0m Trial 8 finished with value: 1.5849056603773586 and parameters: {'alpha': 0.21877246334447975}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,254]\u001b[0m Trial 9 finished with value: 1.5498154981549817 and parameters: {'alpha': 0.34932219273911685}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,283]\u001b[0m Trial 10 finished with value: 1.4334470989761088 and parameters: {'alpha': 0.9639581870061699}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,314]\u001b[0m Trial 11 finished with value: 1.4334470989761092 and parameters: {'alpha': 0.9890054684880925}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,345]\u001b[0m Trial 12 finished with value: 1.4285714285714286 and parameters: {'alpha': 0.7406343119325698}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,375]\u001b[0m Trial 13 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.7943706874760333}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,406]\u001b[0m Trial 14 finished with value: 1.433447098976109 and parameters: {'alpha': 0.5802674957942973}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,435]\u001b[0m Trial 15 finished with value: 1.423728813559322 and parameters: {'alpha': 0.8721056338849471}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,464]\u001b[0m Trial 16 finished with value: 1.443298969072165 and parameters: {'alpha': 0.5542737475719351}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,492]\u001b[0m Trial 17 finished with value: 1.4285714285714286 and parameters: {'alpha': 0.7466137885874623}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,521]\u001b[0m Trial 18 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.8944239469112659}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,550]\u001b[0m Trial 19 finished with value: 1.423728813559322 and parameters: {'alpha': 0.9316620540344402}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,577]\u001b[0m Trial 20 finished with value: 1.4334470989761092 and parameters: {'alpha': 0.6673505195582325}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,608]\u001b[0m Trial 21 finished with value: 1.4285714285714284 and parameters: {'alpha': 0.8271480237873151}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,645]\u001b[0m Trial 22 finished with value: 1.423728813559322 and parameters: {'alpha': 0.9217144494840839}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,675]\u001b[0m Trial 23 finished with value: 1.453287197231834 and parameters: {'alpha': 0.998585949878377}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,704]\u001b[0m Trial 24 finished with value: 1.4634146341463414 and parameters: {'alpha': 0.4545379612772017}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,733]\u001b[0m Trial 25 finished with value: 1.423728813559322 and parameters: {'alpha': 0.8164124400143594}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,762]\u001b[0m Trial 26 finished with value: 1.4383561643835616 and parameters: {'alpha': 0.6309409458704314}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,792]\u001b[0m Trial 27 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.7929135342341382}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,823]\u001b[0m Trial 28 finished with value: 1.4237288135593222 and parameters: {'alpha': 0.7726397698605318}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,855]\u001b[0m Trial 29 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.8909579504213709}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,886]\u001b[0m Trial 30 finished with value: 1.4583333333333333 and parameters: {'alpha': 0.5020812162673911}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:31,969]\u001b[0m Trial 31 finished with value: 1.5384615384615383 and parameters: {'alpha': 0.016672571255416435}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,001]\u001b[0m Trial 32 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.7769630356816094}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,030]\u001b[0m Trial 33 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.887948647252852}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,058]\u001b[0m Trial 34 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.8936883764344027}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,087]\u001b[0m Trial 35 finished with value: 1.4334470989761088 and parameters: {'alpha': 0.9512997141103545}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,115]\u001b[0m Trial 36 finished with value: 1.4285714285714284 and parameters: {'alpha': 0.6990232553653928}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,144]\u001b[0m Trial 37 finished with value: 1.423728813559322 and parameters: {'alpha': 0.8783252441199999}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,172]\u001b[0m Trial 38 finished with value: 1.4383561643835614 and parameters: {'alpha': 0.9908666975802971}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,201]\u001b[0m Trial 39 finished with value: 1.423728813559322 and parameters: {'alpha': 0.8624736404932314}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,229]\u001b[0m Trial 40 finished with value: 1.4285714285714286 and parameters: {'alpha': 0.7421188425643708}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,257]\u001b[0m Trial 41 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.7775089678900975}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,288]\u001b[0m Trial 42 finished with value: 1.4285714285714284 and parameters: {'alpha': 0.8405074950944261}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,319]\u001b[0m Trial 43 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.8040045268464973}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,348]\u001b[0m Trial 44 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.793703193179718}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,377]\u001b[0m Trial 45 finished with value: 1.423728813559322 and parameters: {'alpha': 0.930642588786513}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,407]\u001b[0m Trial 46 finished with value: 1.4334470989761092 and parameters: {'alpha': 0.6932345524615203}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,436]\u001b[0m Trial 47 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.8971151299442656}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,464]\u001b[0m Trial 48 finished with value: 1.453287197231834 and parameters: {'alpha': 0.9987659117120095}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,497]\u001b[0m Trial 49 finished with value: 1.4334470989761088 and parameters: {'alpha': 0.9671357836883759}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,525]\u001b[0m Trial 50 finished with value: 1.4334470989761092 and parameters: {'alpha': 0.6234186767145966}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,554]\u001b[0m Trial 51 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.9036467717073741}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,581]\u001b[0m Trial 52 finished with value: 1.423728813559322 and parameters: {'alpha': 0.8481326399018116}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,610]\u001b[0m Trial 53 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.7936777067978626}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,645]\u001b[0m Trial 54 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.8012543263671813}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,676]\u001b[0m Trial 55 finished with value: 1.4237288135593222 and parameters: {'alpha': 0.7355946662382786}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,709]\u001b[0m Trial 56 finished with value: 1.4285714285714284 and parameters: {'alpha': 0.9372612800905308}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,740]\u001b[0m Trial 57 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.8794915409369782}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,771]\u001b[0m Trial 58 finished with value: 1.4334470989761092 and parameters: {'alpha': 0.6649617977851822}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,801]\u001b[0m Trial 59 finished with value: 1.4285714285714286 and parameters: {'alpha': 0.7270761125294587}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,830]\u001b[0m Trial 60 finished with value: 1.4334470989761088 and parameters: {'alpha': 0.9641354190312852}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,859]\u001b[0m Trial 61 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.8159220955884802}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,888]\u001b[0m Trial 62 finished with value: 1.4285714285714284 and parameters: {'alpha': 0.8229041133904467}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,916]\u001b[0m Trial 63 finished with value: 1.4237288135593222 and parameters: {'alpha': 0.7725752144275584}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,947]\u001b[0m Trial 64 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.7825710743886308}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:32,976]\u001b[0m Trial 65 finished with value: 1.423728813559322 and parameters: {'alpha': 0.8508295682885689}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,008]\u001b[0m Trial 66 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.909113208340556}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,039]\u001b[0m Trial 67 finished with value: 1.5498154981549817 and parameters: {'alpha': 0.3496654136567956}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,069]\u001b[0m Trial 68 finished with value: 1.4285714285714286 and parameters: {'alpha': 0.7596767563545794}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,098]\u001b[0m Trial 69 finished with value: 1.4285714285714286 and parameters: {'alpha': 0.7184711235419892}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,129]\u001b[0m Trial 70 finished with value: 1.4383561643835616 and parameters: {'alpha': 0.6413017691555682}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,159]\u001b[0m Trial 71 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.9026742446786806}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,188]\u001b[0m Trial 72 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.9134028284655751}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,219]\u001b[0m Trial 73 finished with value: 1.423728813559322 and parameters: {'alpha': 0.8595966305428148}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,248]\u001b[0m Trial 74 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.8823048775422632}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,279]\u001b[0m Trial 75 finished with value: 1.4285714285714284 and parameters: {'alpha': 0.8320647023197826}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,310]\u001b[0m Trial 76 finished with value: 1.4334470989761088 and parameters: {'alpha': 0.9628805170037217}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,344]\u001b[0m Trial 77 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.7813205735010222}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,378]\u001b[0m Trial 78 finished with value: 1.4334470989761092 and parameters: {'alpha': 0.6852904917725757}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,411]\u001b[0m Trial 79 finished with value: 1.423728813559322 and parameters: {'alpha': 0.9210108972351727}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,440]\u001b[0m Trial 80 finished with value: 1.4334470989761092 and parameters: {'alpha': 0.5909716449100079}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,470]\u001b[0m Trial 81 finished with value: 1.4285714285714286 and parameters: {'alpha': 0.7620733018341442}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,499]\u001b[0m Trial 82 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.7885020182025866}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,529]\u001b[0m Trial 83 finished with value: 1.423728813559322 and parameters: {'alpha': 0.8200622587100539}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,562]\u001b[0m Trial 84 finished with value: 1.423728813559322 and parameters: {'alpha': 0.8572092712034645}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,595]\u001b[0m Trial 85 finished with value: 1.423728813559322 and parameters: {'alpha': 0.8766157722965271}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,627]\u001b[0m Trial 86 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.8858460855102789}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,663]\u001b[0m Trial 87 finished with value: 1.4285714285714286 and parameters: {'alpha': 0.7131607340999921}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,694]\u001b[0m Trial 88 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.8025163544483996}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,730]\u001b[0m Trial 89 finished with value: 1.4285714285714284 and parameters: {'alpha': 0.9396571979169942}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,764]\u001b[0m Trial 90 finished with value: 1.4285714285714284 and parameters: {'alpha': 0.8243644803653505}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,793]\u001b[0m Trial 91 finished with value: 1.4285714285714284 and parameters: {'alpha': 0.8437052848801987}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,821]\u001b[0m Trial 92 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.8968433094719236}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,850]\u001b[0m Trial 93 finished with value: 1.4285714285714286 and parameters: {'alpha': 0.7590232515663707}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,879]\u001b[0m Trial 94 finished with value: 1.4285714285714284 and parameters: {'alpha': 0.987405381729047}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,907]\u001b[0m Trial 95 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.9132906239328593}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,937]\u001b[0m Trial 96 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.8010446453204411}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,967]\u001b[0m Trial 97 finished with value: 1.423728813559322 and parameters: {'alpha': 0.8720605997063716}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:33,994]\u001b[0m Trial 98 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.8125832416799005}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:48:34,024]\u001b[0m Trial 99 finished with value: 1.4189189189189189 and parameters: {'alpha': 0.7840253987957375}. Best is trial 1 with value: 1.4189189189189189.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "hyper parameter： {'alpha': 0.9035355695351138}\n",
            "AUC： 0.7047619047619048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mURvDSugu6fJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2042030-d291-4c6c-f904-85da31b87c20"
      },
      "source": [
        "# This alpha value is one example of hyperparameter optimization. There are other values that yield a similar AUC value.\n",
        "lasso(0.9035355695351138)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Lasso Regression\n",
            "\n",
            "Sample size of all dataset: 43\n",
            "Sample size of training data: 42     Explanatory variables: (42, 60)   Target value: (42,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 60)   Target value: (1,)\n",
            "\n",
            "AUC: 0.70476   Accuracy: 0.67442   R2: 0.07795\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             6             5\n",
            "Predict False            9            23\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.7047619047619048, 0.6744186046511628, 0.5454545454545454, 0.4,\n",
              "       0.46153846153846156, 0.8214285714285714, list([[6, 5], [9, 23]]),\n",
              "       0.07795414457568717], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBDb2Ubx_FiQ"
      },
      "source": [
        "## 3) Ridge Regression ; AUC 0.660"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUjAy5H3_HzE"
      },
      "source": [
        "def ridge(a):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.linear_model import Ridge\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score\n",
        "\n",
        "    # Rounding of fractional point\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p\n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "    round = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    lr = Ridge(alpha=a)\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        lr.fit(x_train, t_train)\n",
        "        result = lr.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "        # Category of prediction\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "\n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/program/data/cstatdata.csv', index=False)\n",
        "\n",
        "    # Coefficient of Determination\n",
        "    r2 = r2_score(t, pred)\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat = [[TP, FP], [FN, TN]]\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, confmat, r2])\n",
        "\n",
        "    # Output　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. Confusion Matrix, 8. R^2 in LOO)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation with Ridge Regression')\n",
        "    print('')\n",
        "    print('Sample size of all dataset: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('Sample size of training data: ' + str(len(x_train)) + '     Explanatory variables: ' + str(x_train.shape) + '   Target value: ' + str(t_train.shape))\n",
        "    print('Sample size of test data: ' + str(len(x_test)) + '     Explanatory variables: ' + str(x_test.shape) + '   Target value: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO')\n",
        "    print('')\n",
        "\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zir3sUM_2W5"
      },
      "source": [
        "### Optimization with Optuna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI25pyN4_xxC"
      },
      "source": [
        "def ridgeOptuna(trial):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.linear_model import Ridge\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    import optuna\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "\n",
        "    alpha = trial.suggest_uniform('alpha', 1, 1000)\n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    lr = Ridge(alpha=alpha)\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        lr.fit(x_train, t_train)\n",
        "        result = lr.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    res = auc\n",
        "    # minimize 1/AUC　\n",
        "    return 1/res\n",
        "\n",
        "\n",
        "def ridgeTrial(n_trials):\n",
        "    import optuna\n",
        "    study = optuna.create_study()\n",
        "    study.optimize(ridgeOptuna, n_trials)\n",
        "    # result\n",
        "    print()\n",
        "    print('hpyterparameter：', study.best_params)\n",
        "    print('AUC：', 1/study.best_value)\n",
        "    print()\n",
        "    return study.best_params['alpha']    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnCYS4sl4viA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbeb14af-10a0-4c2b-db64-7fd5ab667a82"
      },
      "source": [
        "ridgeTrial(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-04 09:49:24,339]\u001b[0m A new study created in memory with name: no-name-d6479cfe-b1c4-4014-9310-c1f25c869cb1\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:24,396]\u001b[0m Trial 0 finished with value: 1.532846715328467 and parameters: {'alpha': 685.1140537930773}. Best is trial 0 with value: 1.532846715328467.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:24,440]\u001b[0m Trial 1 finished with value: 1.5384615384615383 and parameters: {'alpha': 96.83243349038307}. Best is trial 0 with value: 1.532846715328467.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:24,483]\u001b[0m Trial 2 finished with value: 1.5671641791044777 and parameters: {'alpha': 145.53912843187686}. Best is trial 0 with value: 1.532846715328467.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:24,524]\u001b[0m Trial 3 finished with value: 1.5613382899628254 and parameters: {'alpha': 273.65045770049875}. Best is trial 0 with value: 1.532846715328467.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:24,565]\u001b[0m Trial 4 finished with value: 1.5671641791044777 and parameters: {'alpha': 279.81476347536506}. Best is trial 0 with value: 1.532846715328467.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:24,606]\u001b[0m Trial 5 finished with value: 1.5217391304347827 and parameters: {'alpha': 488.4251003378692}. Best is trial 5 with value: 1.5217391304347827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:24,649]\u001b[0m Trial 6 finished with value: 1.532846715328467 and parameters: {'alpha': 654.0948101383759}. Best is trial 5 with value: 1.5217391304347827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:24,692]\u001b[0m Trial 7 finished with value: 1.5328467153284673 and parameters: {'alpha': 767.9837330893756}. Best is trial 5 with value: 1.5217391304347827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:24,733]\u001b[0m Trial 8 finished with value: 1.5730337078651686 and parameters: {'alpha': 160.5481334784721}. Best is trial 5 with value: 1.5217391304347827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:24,774]\u001b[0m Trial 9 finished with value: 1.5217391304347827 and parameters: {'alpha': 923.9067542067253}. Best is trial 5 with value: 1.5217391304347827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:24,819]\u001b[0m Trial 10 finished with value: 1.5217391304347827 and parameters: {'alpha': 471.3375487924234}. Best is trial 5 with value: 1.5217391304347827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:24,858]\u001b[0m Trial 11 finished with value: 1.5217391304347827 and parameters: {'alpha': 956.6503195250357}. Best is trial 5 with value: 1.5217391304347827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:24,906]\u001b[0m Trial 12 finished with value: 1.5217391304347827 and parameters: {'alpha': 479.2308274785694}. Best is trial 5 with value: 1.5217391304347827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:24,952]\u001b[0m Trial 13 finished with value: 1.5328467153284673 and parameters: {'alpha': 913.480791943763}. Best is trial 5 with value: 1.5217391304347827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:24,993]\u001b[0m Trial 14 finished with value: 1.5217391304347827 and parameters: {'alpha': 570.6040065638838}. Best is trial 5 with value: 1.5217391304347827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,034]\u001b[0m Trial 15 finished with value: 1.5613382899628254 and parameters: {'alpha': 343.80676140025923}. Best is trial 5 with value: 1.5217391304347827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,073]\u001b[0m Trial 16 finished with value: 1.5272727272727276 and parameters: {'alpha': 834.7623174334943}. Best is trial 5 with value: 1.5217391304347827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,125]\u001b[0m Trial 17 finished with value: 1.5217391304347827 and parameters: {'alpha': 592.9542925950468}. Best is trial 5 with value: 1.5217391304347827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,165]\u001b[0m Trial 18 finished with value: 1.5272727272727273 and parameters: {'alpha': 639.7780993951411}. Best is trial 5 with value: 1.5217391304347827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,204]\u001b[0m Trial 19 finished with value: 1.5217391304347827 and parameters: {'alpha': 984.1063493938077}. Best is trial 5 with value: 1.5217391304347827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,248]\u001b[0m Trial 20 finished with value: 1.5272727272727276 and parameters: {'alpha': 811.737294985884}. Best is trial 5 with value: 1.5217391304347827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,288]\u001b[0m Trial 21 finished with value: 1.5217391304347827 and parameters: {'alpha': 543.1564208020333}. Best is trial 5 with value: 1.5217391304347827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,328]\u001b[0m Trial 22 finished with value: 1.532846715328467 and parameters: {'alpha': 432.6030252829449}. Best is trial 5 with value: 1.5217391304347827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,368]\u001b[0m Trial 23 finished with value: 1.5217391304347827 and parameters: {'alpha': 997.2726200487064}. Best is trial 5 with value: 1.5217391304347827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,408]\u001b[0m Trial 24 finished with value: 1.5217391304347827 and parameters: {'alpha': 993.0243463774164}. Best is trial 5 with value: 1.5217391304347827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,448]\u001b[0m Trial 25 finished with value: 1.4634146341463414 and parameters: {'alpha': 18.77350065987713}. Best is trial 25 with value: 1.4634146341463414.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,493]\u001b[0m Trial 26 finished with value: 1.4788732394366195 and parameters: {'alpha': 14.03949597451367}. Best is trial 25 with value: 1.4634146341463414.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,536]\u001b[0m Trial 27 finished with value: 1.4482758620689655 and parameters: {'alpha': 33.68283581555988}. Best is trial 27 with value: 1.4482758620689655.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,576]\u001b[0m Trial 28 finished with value: 1.5217391304347827 and parameters: {'alpha': 9.304397721026303}. Best is trial 27 with value: 1.4482758620689655.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,616]\u001b[0m Trial 29 finished with value: 1.4840989399293287 and parameters: {'alpha': 13.955498380623194}. Best is trial 27 with value: 1.4482758620689655.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,656]\u001b[0m Trial 30 finished with value: 1.510791366906475 and parameters: {'alpha': 67.96463257796717}. Best is trial 27 with value: 1.4482758620689655.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,696]\u001b[0m Trial 31 finished with value: 1.4840989399293287 and parameters: {'alpha': 12.741189503211444}. Best is trial 27 with value: 1.4482758620689655.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,736]\u001b[0m Trial 32 finished with value: 1.5328467153284673 and parameters: {'alpha': 83.30856548173787}. Best is trial 27 with value: 1.4482758620689655.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,777]\u001b[0m Trial 33 finished with value: 1.5789473684210527 and parameters: {'alpha': 191.86095833047028}. Best is trial 27 with value: 1.4482758620689655.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,818]\u001b[0m Trial 34 finished with value: 1.5909090909090913 and parameters: {'alpha': 3.6433030169761764}. Best is trial 27 with value: 1.4482758620689655.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,862]\u001b[0m Trial 35 finished with value: 1.5441176470588238 and parameters: {'alpha': 110.3344204513154}. Best is trial 27 with value: 1.4482758620689655.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,903]\u001b[0m Trial 36 finished with value: 1.5671641791044777 and parameters: {'alpha': 216.74377779178877}. Best is trial 27 with value: 1.4482758620689655.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:25,943]\u001b[0m Trial 37 finished with value: 1.443298969072165 and parameters: {'alpha': 38.73764326244461}. Best is trial 37 with value: 1.443298969072165.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,006]\u001b[0m Trial 38 finished with value: 1.5671641791044777 and parameters: {'alpha': 254.2041014830866}. Best is trial 37 with value: 1.443298969072165.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,049]\u001b[0m Trial 39 finished with value: 1.4736842105263157 and parameters: {'alpha': 57.7982449533785}. Best is trial 37 with value: 1.443298969072165.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,091]\u001b[0m Trial 40 finished with value: 1.5555555555555558 and parameters: {'alpha': 126.55022544409621}. Best is trial 37 with value: 1.443298969072165.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,146]\u001b[0m Trial 41 finished with value: 1.4583333333333333 and parameters: {'alpha': 51.96833032471658}. Best is trial 37 with value: 1.443298969072165.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,187]\u001b[0m Trial 42 finished with value: 1.4840989399293285 and parameters: {'alpha': 62.71553781957941}. Best is trial 37 with value: 1.443298969072165.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,228]\u001b[0m Trial 43 finished with value: 1.5730337078651686 and parameters: {'alpha': 174.52481778896703}. Best is trial 37 with value: 1.443298969072165.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,269]\u001b[0m Trial 44 finished with value: 1.4583333333333333 and parameters: {'alpha': 51.55310137506643}. Best is trial 37 with value: 1.443298969072165.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,310]\u001b[0m Trial 45 finished with value: 1.5613382899628254 and parameters: {'alpha': 336.7198608931541}. Best is trial 37 with value: 1.443298969072165.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,350]\u001b[0m Trial 46 finished with value: 1.5671641791044775 and parameters: {'alpha': 141.4957211455656}. Best is trial 37 with value: 1.443298969072165.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,394]\u001b[0m Trial 47 finished with value: 1.453287197231834 and parameters: {'alpha': 53.47432224656559}. Best is trial 37 with value: 1.443298969072165.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,439]\u001b[0m Trial 48 finished with value: 1.5671641791044777 and parameters: {'alpha': 234.15890991714036}. Best is trial 37 with value: 1.443298969072165.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,482]\u001b[0m Trial 49 finished with value: 1.5613382899628254 and parameters: {'alpha': 323.5709462967512}. Best is trial 37 with value: 1.443298969072165.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,523]\u001b[0m Trial 50 finished with value: 1.5498154981549817 and parameters: {'alpha': 116.96780744663536}. Best is trial 37 with value: 1.443298969072165.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,564]\u001b[0m Trial 51 finished with value: 1.4383561643835616 and parameters: {'alpha': 45.842793423248956}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,606]\u001b[0m Trial 52 finished with value: 1.4583333333333333 and parameters: {'alpha': 51.767312413139344}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,647]\u001b[0m Trial 53 finished with value: 1.5441176470588234 and parameters: {'alpha': 93.12072597445282}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,688]\u001b[0m Trial 54 finished with value: 1.5730337078651686 and parameters: {'alpha': 173.53317941177102}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,730]\u001b[0m Trial 55 finished with value: 1.443298969072165 and parameters: {'alpha': 39.35283671962128}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,771]\u001b[0m Trial 56 finished with value: 1.5730337078651686 and parameters: {'alpha': 143.9481750257701}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,812]\u001b[0m Trial 57 finished with value: 1.5384615384615383 and parameters: {'alpha': 101.11685525828287}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,853]\u001b[0m Trial 58 finished with value: 1.5613382899628254 and parameters: {'alpha': 297.952766575797}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,894]\u001b[0m Trial 59 finished with value: 1.443298969072165 and parameters: {'alpha': 41.23412375531933}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,935]\u001b[0m Trial 60 finished with value: 1.5498154981549817 and parameters: {'alpha': 399.11511018722774}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:26,976]\u001b[0m Trial 61 finished with value: 1.4383561643835616 and parameters: {'alpha': 42.67050281244463}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,018]\u001b[0m Trial 62 finished with value: 1.453287197231834 and parameters: {'alpha': 25.152395780940186}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,059]\u001b[0m Trial 63 finished with value: 1.4583333333333333 and parameters: {'alpha': 27.26675755655485}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,100]\u001b[0m Trial 64 finished with value: 1.7213114754098362 and parameters: {'alpha': 1.1948306635668828}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,152]\u001b[0m Trial 65 finished with value: 1.5441176470588234 and parameters: {'alpha': 94.90757116101794}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,196]\u001b[0m Trial 66 finished with value: 1.5730337078651686 and parameters: {'alpha': 159.43738818337962}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,237]\u001b[0m Trial 67 finished with value: 1.5789473684210527 and parameters: {'alpha': 195.72363910984626}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,279]\u001b[0m Trial 68 finished with value: 1.4482758620689655 and parameters: {'alpha': 39.71805689888917}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,320]\u001b[0m Trial 69 finished with value: 1.5384615384615388 and parameters: {'alpha': 729.4904328187166}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,361]\u001b[0m Trial 70 finished with value: 1.5613382899628254 and parameters: {'alpha': 134.54848273652877}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,402]\u001b[0m Trial 71 finished with value: 1.4482758620689655 and parameters: {'alpha': 32.44406005775422}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,444]\u001b[0m Trial 72 finished with value: 1.5328467153284673 and parameters: {'alpha': 84.84035221314008}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,487]\u001b[0m Trial 73 finished with value: 1.4482758620689655 and parameters: {'alpha': 36.19715239344538}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,530]\u001b[0m Trial 74 finished with value: 1.5272727272727276 and parameters: {'alpha': 76.95638121721007}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,573]\u001b[0m Trial 75 finished with value: 1.590909090909091 and parameters: {'alpha': 4.856195260420321}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,617]\u001b[0m Trial 76 finished with value: 1.4383561643835616 and parameters: {'alpha': 44.82748694100212}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,665]\u001b[0m Trial 77 finished with value: 1.5498154981549817 and parameters: {'alpha': 115.9814299171085}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,711]\u001b[0m Trial 78 finished with value: 1.443298969072165 and parameters: {'alpha': 36.79736271873705}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,754]\u001b[0m Trial 79 finished with value: 1.5272727272727276 and parameters: {'alpha': 75.87869553106681}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,797]\u001b[0m Trial 80 finished with value: 1.5789473684210527 and parameters: {'alpha': 5.62372216502062}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,842]\u001b[0m Trial 81 finished with value: 1.4482758620689655 and parameters: {'alpha': 33.810571128601}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,892]\u001b[0m Trial 82 finished with value: 1.5272727272727276 and parameters: {'alpha': 73.29567883254266}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,939]\u001b[0m Trial 83 finished with value: 1.5498154981549817 and parameters: {'alpha': 111.14302323498214}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:27,982]\u001b[0m Trial 84 finished with value: 1.443298969072165 and parameters: {'alpha': 36.76626917853156}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:28,025]\u001b[0m Trial 85 finished with value: 1.7355371900826448 and parameters: {'alpha': 1.1565418595363184}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:28,070]\u001b[0m Trial 86 finished with value: 1.5730337078651686 and parameters: {'alpha': 157.5779933359057}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:28,112]\u001b[0m Trial 87 finished with value: 1.4482758620689655 and parameters: {'alpha': 49.29463047608901}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:28,172]\u001b[0m Trial 88 finished with value: 1.4840989399293285 and parameters: {'alpha': 62.54156689470753}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:28,216]\u001b[0m Trial 89 finished with value: 1.5613382899628254 and parameters: {'alpha': 129.53294034974937}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:28,259]\u001b[0m Trial 90 finished with value: 1.5441176470588234 and parameters: {'alpha': 90.9627299304269}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:28,302]\u001b[0m Trial 91 finished with value: 1.4482758620689655 and parameters: {'alpha': 32.634661661225344}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:28,346]\u001b[0m Trial 92 finished with value: 1.453287197231834 and parameters: {'alpha': 50.563263097824766}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:28,389]\u001b[0m Trial 93 finished with value: 1.6091954022988508 and parameters: {'alpha': 3.243616642613823}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:28,439]\u001b[0m Trial 94 finished with value: 1.4583333333333333 and parameters: {'alpha': 26.38350255491164}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:28,484]\u001b[0m Trial 95 finished with value: 1.5441176470588238 and parameters: {'alpha': 104.01220095410092}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:28,526]\u001b[0m Trial 96 finished with value: 1.4999999999999998 and parameters: {'alpha': 65.2276660919608}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:28,569]\u001b[0m Trial 97 finished with value: 1.4482758620689655 and parameters: {'alpha': 35.90591056395266}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:28,611]\u001b[0m Trial 98 finished with value: 1.647058823529412 and parameters: {'alpha': 2.7113361815844286}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 09:49:28,653]\u001b[0m Trial 99 finished with value: 1.5272727272727276 and parameters: {'alpha': 73.4531093066395}. Best is trial 51 with value: 1.4383561643835616.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "hpyterparameter： {'alpha': 45.842793423248956}\n",
            "AUC： 0.6952380952380952\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "45.842793423248956"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfJar0PTwX8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eca0a6c-b48a-486a-d9a9-938b637c6883"
      },
      "source": [
        "# This alpha value is one example of hyperparameter optimization. There are other values that yield a similar AUC value.\n",
        "ridge(71.79566461970718)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Ridge Regression\n",
            "\n",
            "Sample size of all dataset: 43\n",
            "Sample size of training data: 42     Explanatory variables: (42, 60)   Target value: (42,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 60)   Target value: (1,)\n",
            "\n",
            "AUC: 0.65952   Accuracy: 0.67442   R2: -2.4232\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             9             8\n",
            "Predict False            6            20\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.6595238095238095, 0.6744186046511628, 0.5294117647058824, 0.6,\n",
              "       0.5625, 0.7142857142857143, list([[9, 8], [6, 20]]),\n",
              "       -2.4231978816962556], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA_PFDJnGnrH"
      },
      "source": [
        "## 4) Logistic Regression ; AUC 0.662\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKKZIYvYOeQE"
      },
      "source": [
        "# Scaling with Normalization using MaxMin\n",
        "\n",
        "def logisticN():\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score\n",
        "\n",
        "    # Rounding of fractional point\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p    \n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "    round = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler.fit(x)\n",
        "    x = scaler.transform(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    lr = LogisticRegression()\n",
        "\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        lr.fit(x_train, t_train)\n",
        "        result = lr.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "        # Category of prediction\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "\n",
        "\n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/program/data/cstatdata.csv', index=False)\n",
        "\n",
        "    # Coefficient of Determination\n",
        "    r2 = r2_score(t, pred)\n",
        "\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "    \n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat = [[TP, FP], [FN, TN]]\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, [[TP, FP], [FN, TN]], r2]  )\n",
        "\n",
        "    # Output　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. Confusion Matrix, 8. R^2 in LOO)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation with Logistic Regression with Normalization')\n",
        "    print('')\n",
        "    print('Sample size of all dataset: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('Sample size of training data: ' + str(len(x_train)) + '     Explanatory variables: ' + str(x_train.shape) + '   Target value: ' + str(t_train.shape))\n",
        "    print('Sample size of test data: ' + str(len(x_test)) + '     Explanatory variables: ' + str(x_test.shape) + '   Target value: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO')\n",
        "    print('')\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Scaling with Standardization\n",
        "\n",
        "def logisticS():\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.linear_model import LogisticRegression\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score\n",
        "\n",
        "    # Rounding of fractional point\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p    \n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "    round = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    scaler = StandardScaler() \n",
        "    scaler.fit(x)  \n",
        "    x = scaler.transform(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    lr = LogisticRegression()\n",
        "\n",
        "\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        lr.fit(x_train, t_train)\n",
        "        result = lr.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "        # Category of prediction\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "       \n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/program/data/cstatdata.csv', index=False)\n",
        "\n",
        "    # Coefficient of Determination\n",
        "    r2 = r2_score(t, pred)\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        " \n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat = [[TP, FP], [FN, TN]]\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "    \n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, [[TP, FP], [FN, TN]], r2]  )\n",
        "\n",
        "    # Output　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. Confusion Matrix, 8. R^2 in LOO)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation with Logistic Regression with Standardization')\n",
        "    print('')\n",
        "    print('Sample size of all dataset: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('Sample size of training data: ' + str(len(x_train)) + '     Explanatory variables: ' + str(x_train.shape) + '   Target value: ' + str(t_train.shape))\n",
        "    print('Sample size of test data: ' + str(len(x_test)) + '     Explanatory variables: ' + str(x_test.shape) + '   Target value: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO')\n",
        "    print('')\n",
        "\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usE_YMhTPTmC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fb25f2c-4123-47d5-870e-2b4148329372"
      },
      "source": [
        "logisticN()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Logistic Regression with Normalization\n",
            "\n",
            "Sample size of all dataset: 43\n",
            "Sample size of training data: 42     Explanatory variables: (42, 60)   Target value: (42,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 60)   Target value: (1,)\n",
            "\n",
            "AUC: 0.6619   Accuracy: 0.72093   R2: -0.22857\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             7             4\n",
            "Predict False            8            24\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.661904761904762, 0.7209302325581395, 0.6363636363636364,\n",
              "       0.4666666666666667, 0.5384615384615384, 0.8571428571428571,\n",
              "       list([[7, 4], [8, 24]]), -0.22857142857142843], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzOgSfrtPWAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a752ca-046e-4576-9694-113e8e012833"
      },
      "source": [
        "logisticS()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Logistic Regression with Standardization\n",
            "\n",
            "Sample size of all dataset: 43\n",
            "Sample size of training data: 42     Explanatory variables: (42, 60)   Target value: (42,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 60)   Target value: (1,)\n",
            "\n",
            "AUC: 0.61071   Accuracy: 0.67442   R2: -0.43333\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             6             5\n",
            "Predict False            9            23\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.6107142857142857, 0.6744186046511628, 0.5454545454545454, 0.4,\n",
              "       0.46153846153846156, 0.8214285714285714, list([[6, 5], [9, 23]]),\n",
              "       -0.4333333333333331], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15XXh2sJGv3s"
      },
      "source": [
        "## 5) Support Vector Machine ; AUC 0.721"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1Z9ztLKQnpK"
      },
      "source": [
        "# Normalization\n",
        "\n",
        "def SVMn():\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.svm import SVC\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score\n",
        "\n",
        "    # Rounding of fractional point\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p\n",
        "\n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "    round = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    scaler = MinMaxScaler()\n",
        "    scaler.fit(x)\n",
        "    x = scaler.transform(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    svm = SVC()\n",
        "\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        svm.fit(x_train, t_train)\n",
        "        result = svm.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "\n",
        "        # Category of prediction\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "\n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/program/data/cstatdata.csv', index=False)\n",
        "\n",
        "    # Coefficient of Determination\n",
        "    r2 = r2_score(t, pred)\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat = [[TP, FP], [FN, TN]]\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, [[TP, FP], [FN, TN]], r2])\n",
        "\n",
        "    # Output　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. Confusion Matrix, 8. R^2 in LOO)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation with Support Vector Machine with Normalizatioin')\n",
        "    print('')\n",
        "    print('Sample size of all dataset: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('Sample size of training data: ' + str(len(x_train)) + '     Explanatory variables: ' + str(x_train.shape) + '   Target value: ' + str(t_train.shape))\n",
        "    print('Sample size of test data: ' + str(len(x_test)) + '     Explanatory variables: ' + str(x_test.shape) + '   Target value: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO')\n",
        "    print('')\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "# Standardization\n",
        "\n",
        "def SVMs():\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.svm import SVC\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score    \n",
        "\n",
        "    # Rounding of fractional point\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p\n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "    round = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    scaler = StandardScaler() \n",
        "    scaler.fit(x)  \n",
        "    x = scaler.transform(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    svm = SVC()\n",
        "\n",
        "\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        svm.fit(x_train, t_train)\n",
        "        result = svm.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "        # Category of prediction\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "  \n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/program/data/cstatdata.csv', index=False)\n",
        "\n",
        "    # Coefficient of Determination\n",
        "    r2 = r2_score(t, pred)\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat = [[TP, FP], [FN, TN]]\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "    \n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, [[TP, FP], [FN, TN]], r2])\n",
        "\n",
        "    # Output　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. Confusion Matrix, 8. R^2 in LOO)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation with Support Vector Machine with Standardizatioin')\n",
        "    print('')\n",
        "    print('Sample size of all dataset: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('Sample size of training data: ' + str(len(x_train)) + '     Explanatory variables: ' + str(x_train.shape) + '   Target value: ' + str(t_train.shape))\n",
        "    print('Sample size of test data: ' + str(len(x_test)) + '     Explanatory variables: ' + str(x_test.shape) + '   Target value: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO')\n",
        "    print('')\n",
        "\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg6EaiGoQ98P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cbe6835-304b-47e9-98b0-1a547fa23f31"
      },
      "source": [
        "SVMn()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Support Vector Machine with Normalizatioin\n",
            "\n",
            "Sample size of all dataset: 43\n",
            "Sample size of training data: 42     Explanatory variables: (42, 60)   Target value: (42,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 60)   Target value: (1,)\n",
            "\n",
            "AUC: 0.61548   Accuracy: 0.72093   R2: -0.22857\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             4             1\n",
            "Predict False           11            27\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.6154761904761904, 0.7209302325581395, 0.8, 0.26666666666666666,\n",
              "       0.4, 0.9642857142857143, list([[4, 1], [11, 27]]),\n",
              "       -0.22857142857142843], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhd8LEYJRDz7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84060c7b-2a01-4dee-b50c-be8bd03f489c"
      },
      "source": [
        "SVMs()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Support Vector Machine with Standardizatioin\n",
            "\n",
            "Sample size of all dataset: 43\n",
            "Sample size of training data: 42     Explanatory variables: (42, 60)   Target value: (42,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 60)   Target value: (1,)\n",
            "\n",
            "AUC: 0.6   Accuracy: 0.72093   R2: -0.22857\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             3             0\n",
            "Predict False           12            28\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.6, 0.7209302325581395, 1.0, 0.2, 0.3333333333333333, 1.0,\n",
              "       list([[3, 0], [12, 28]]), -0.22857142857142843], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OV7FvV2zGzo-"
      },
      "source": [
        "## 6) Random Forest ; AUC 0.749"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abt5RB5PRT5p"
      },
      "source": [
        "def randomF(random_state):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score\n",
        "\n",
        "    # Rounding of fractional point\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p    \n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "    round = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    rf = RandomForestClassifier(random_state=random_state)\n",
        "  \n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        rf.fit(x_train, t_train)\n",
        "        result = rf.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "        # Category of prediction\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "\n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/program/data/cstatdata.csv', index=False)\n",
        "\n",
        "    # Coefficient of Determination\n",
        "    r2 = r2_score(t, pred)\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat = [[TP, FP], [FN, TN]]\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, [[TP, FP], [FN, TN]], r2])\n",
        "\n",
        "    # Output　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. Confusion Matrix, 8. R^2 in LOO)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation with Random Forest')\n",
        "    print('')\n",
        "    print('Sample size of all dataset: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('Sample size of training data: ' + str(len(x_train)) + '     Explanatory variables: ' + str(x_train.shape) + '   Target value: ' + str(t_train.shape))\n",
        "    print('Sample size of test data: ' + str(len(x_test)) + '     Explanatory variables: ' + str(x_test.shape) + '   Target value: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO')\n",
        "    print('')\n",
        "\n",
        "#    from pprint import pprint\n",
        "#    print('◆ The defalut settings of the hyperparameters')\n",
        "#    pprint(rf.get_params())  \n",
        "    # n_estimators, max_features should be optimized first\n",
        "    # then, max_depth, min_sample_split, min_samples_leaf, bootstrap\n",
        "\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YirI1_ICkSf9"
      },
      "source": [
        "### Optimization with RandomizedSearchCV & GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeNHMUEQncIa"
      },
      "source": [
        "#### A. RandomSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTNEspFAES4Y"
      },
      "source": [
        "def RandomSearch(variables, label):\n",
        "    from sklearn.model_selection import RandomizedSearchCV\n",
        "    from pprint import pprint\n",
        "\n",
        "    # Number of trees in random forest\n",
        "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "    # Number of features to consider at every split\n",
        "    max_features = ['auto', 'sqrt']\n",
        "    # Maximum number of levels in tree\n",
        "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "    max_depth.append(None)\n",
        "    # Minimum number of samples required to split a node\n",
        "    min_samples_split = [2, 5, 10]\n",
        "    # Minimum number of samples required at each leaf node\n",
        "    min_samples_leaf = [1, 2, 4]\n",
        "    # Method of selecting samples for training each tree\n",
        "    bootstrap = [True, False]\n",
        "\n",
        "    # Create the random grid\n",
        "    random_grid = {'n_estimators': n_estimators,\n",
        "                  'max_features': max_features,\n",
        "                  'max_depth': max_depth,\n",
        "                  'min_samples_split': min_samples_split,\n",
        "                  'min_samples_leaf': min_samples_leaf,\n",
        "                  'bootstrap': bootstrap}\n",
        "\n",
        "    print('◆　Random Hypterparameter Grid')\n",
        "    pprint(random_grid)\n",
        "    print('')\n",
        "\n",
        "    # Use the random grid to search for best hyperparameters\n",
        "    # First create the base model to tune\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    rf = RandomForestClassifier()\n",
        "    # Random search of parameters, using 3 fold cross validation, \n",
        "    # search across 100 different combinations, and use all available cores\n",
        "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "    # Fit the random search model\n",
        "    rf_random.fit(variables, label)\n",
        "    print('')\n",
        "    print('◆　Best Parameters using RandomizedSearchCV')\n",
        "    pprint(rf_random.best_params_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PQ-q8h0gA63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e745c30-3f65-4b73-f162-8c42275cc7d5"
      },
      "source": [
        "RandomSearch(x, t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "◆　Random Hypterparameter Grid\n",
            "{'bootstrap': [True, False],\n",
            " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
            " 'max_features': ['auto', 'sqrt'],\n",
            " 'min_samples_leaf': [1, 2, 4],\n",
            " 'min_samples_split': [2, 5, 10],\n",
            " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n",
            "\n",
            "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   42.2s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  5.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "◆　Best Parameters using RandomizedSearchCV\n",
            "{'bootstrap': True,\n",
            " 'max_depth': 50,\n",
            " 'max_features': 'sqrt',\n",
            " 'min_samples_leaf': 1,\n",
            " 'min_samples_split': 2,\n",
            " 'n_estimators': 200}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQEK4rlqngIk"
      },
      "source": [
        "#### B. GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtRLFrmsghl6"
      },
      "source": [
        " def GridSearch(variables, label):\n",
        "    from sklearn.model_selection import GridSearchCV\n",
        "    from pprint import pprint\n",
        "    # Create the parameter grid based on the results of random search \n",
        "    param_grid = {\n",
        "        'bootstrap': [True],\n",
        "        'max_depth': [20,30,40],\n",
        "        'max_features': ['sqrt'],\n",
        "        'min_samples_leaf': [1,2,3],\n",
        "        'min_samples_split': [4,5,6],\n",
        "        'n_estimators': [300,400,500]\n",
        "    }\n",
        "    # Create a based model\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    rf = RandomForestClassifier()\n",
        "    # Instantiate the grid search model\n",
        "    grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
        "                              cv = 3, n_jobs = -1, verbose = 2)\n",
        "    # Fit the grid search to the data\n",
        "    grid_search.fit(variables, label)\n",
        "    print('')\n",
        "    print('◆　Best Parameters using GridSearchCV')\n",
        "    pprint(grid_search.best_params_)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpOWLFnloQfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27fb4e6d-a684-4eea-ae46-4885fd2bc63b"
      },
      "source": [
        "GridSearch(x, t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   16.9s\n",
            "[Parallel(n_jobs=-1)]: Done 158 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed:  1.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "◆　Best Parameters using GridSearchCV\n",
            "{'bootstrap': True,\n",
            " 'max_depth': 20,\n",
            " 'max_features': 'sqrt',\n",
            " 'min_samples_leaf': 2,\n",
            " 'min_samples_split': 5,\n",
            " 'n_estimators': 300}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqSgGsBApmvG"
      },
      "source": [
        "def randomforest(random_state, bootstrap, max_depth, max_features, min_samples_leaf, min_samples_split, n_estimators):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score\n",
        "\n",
        "    # Rounding of fractional point\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p    \n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "    round = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    rf = RandomForestClassifier(random_state=random_state,\n",
        "                                bootstrap = True,\n",
        "                                max_depth = 20,\n",
        "                                max_features = 'sqrt',\n",
        "                                min_samples_leaf = 1,\n",
        "                                min_samples_split = 4,\n",
        "                                n_estimators = 300\n",
        "                                )\n",
        "  \n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        rf.fit(x_train, t_train)\n",
        "        result = rf.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "        # Category of prediction\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "\n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/practice/data/newMaxGD2.csv', index=False)\n",
        "\n",
        "    # Coefficient of Determination\n",
        "    r2 = r2_score(t, pred)\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat = [[TP, FP], [FN, TN]]\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, [[TP, FP], [FN, TN]], r2])\n",
        "\n",
        "    # Output　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. Confusion Matrix, 8. R^2 in LOO)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation with Random Forest')\n",
        "    print('')\n",
        "    print('Sample size of all dataset: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('Sample size of training data: ' + str(len(x_train)) + '     Explanatory variables: ' + str(x_train.shape) + '   Target value: ' + str(t_train.shape))\n",
        "    print('Sample size of test data: ' + str(len(x_test)) + '     Explanatory variables: ' + str(x_test.shape) + '   Target value: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO')\n",
        "    print('')\n",
        "\n",
        "    from pprint import pprint\n",
        "    print('◆ The settings of the hyperparameters')\n",
        "    pprint(rf.get_params())  \n",
        "    # n_estimators, max_features should be optimized first\n",
        "    # then, max_depth, min_sample_split, min_samples_leaf, bootstrap\n",
        "    print('')\n",
        "\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERzGt433veK9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29d3d293-fbab-4b88-ccc8-9eefc3d1cd1f"
      },
      "source": [
        "randomforest(41, True, 50, 'sqrt', 1, 2, 200)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Random Forest\n",
            "\n",
            "Sample size of all dataset: 43\n",
            "Sample size of training data: 42     Explanatory variables: (42, 60)   Target value: (42,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 60)   Target value: (1,)\n",
            "\n",
            "AUC: 0.59762   Accuracy: 0.69767   R2: -0.33095\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             4             2\n",
            "Predict False           11            26\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n",
            "◆ The settings of the hyperparameters\n",
            "{'bootstrap': True,\n",
            " 'ccp_alpha': 0.0,\n",
            " 'class_weight': None,\n",
            " 'criterion': 'gini',\n",
            " 'max_depth': 20,\n",
            " 'max_features': 'sqrt',\n",
            " 'max_leaf_nodes': None,\n",
            " 'max_samples': None,\n",
            " 'min_impurity_decrease': 0.0,\n",
            " 'min_impurity_split': None,\n",
            " 'min_samples_leaf': 1,\n",
            " 'min_samples_split': 4,\n",
            " 'min_weight_fraction_leaf': 0.0,\n",
            " 'n_estimators': 300,\n",
            " 'n_jobs': None,\n",
            " 'oob_score': False,\n",
            " 'random_state': 41,\n",
            " 'verbose': 0,\n",
            " 'warm_start': False}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5976190476190476, 0.6976744186046512, 0.6666666666666666,\n",
              "       0.26666666666666666, 0.38095238095238093, 0.9285714285714286,\n",
              "       list([[4, 2], [11, 26]]), -0.33095238095238066], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNcNheedzcj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4245ffe-9ebf-43f5-d23c-4896172894a5"
      },
      "source": [
        "randomforest(625, False, 20, 'sqrt', 1, 4, 300)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Random Forest\n",
            "\n",
            "Sample size of all dataset: 43\n",
            "Sample size of training data: 42     Explanatory variables: (42, 60)   Target value: (42,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 60)   Target value: (1,)\n",
            "\n",
            "AUC: 0.63095   Accuracy: 0.72093   R2: -0.22857\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             5             2\n",
            "Predict False           10            26\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n",
            "◆ The settings of the hyperparameters\n",
            "{'bootstrap': True,\n",
            " 'ccp_alpha': 0.0,\n",
            " 'class_weight': None,\n",
            " 'criterion': 'gini',\n",
            " 'max_depth': 20,\n",
            " 'max_features': 'sqrt',\n",
            " 'max_leaf_nodes': None,\n",
            " 'max_samples': None,\n",
            " 'min_impurity_decrease': 0.0,\n",
            " 'min_impurity_split': None,\n",
            " 'min_samples_leaf': 1,\n",
            " 'min_samples_split': 4,\n",
            " 'min_weight_fraction_leaf': 0.0,\n",
            " 'n_estimators': 300,\n",
            " 'n_jobs': None,\n",
            " 'oob_score': False,\n",
            " 'random_state': 625,\n",
            " 'verbose': 0,\n",
            " 'warm_start': False}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.6309523809523809, 0.7209302325581395, 0.7142857142857143,\n",
              "       0.3333333333333333, 0.45454545454545453, 0.9285714285714286,\n",
              "       list([[5, 2], [10, 26]]), -0.22857142857142843], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g110jeBzTtRz"
      },
      "source": [
        "### Optimization with Optuna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTUzS_FYTQhg"
      },
      "source": [
        "def randomFOptuna(trial):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "    import optuna\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "\n",
        "    random_state = trial.suggest_int('random_state', 1, 2000)\n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    pred = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    rf = RandomForestClassifier(random_state = random_state)\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        rf.fit(x_train, t_train)\n",
        "        result = rf.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    # minimize 1/AUC\n",
        "    return 1/auc\n",
        "\n",
        "\n",
        "def randomFTrial(n_trials):\n",
        "    import optuna\n",
        "    study = optuna.create_study()\n",
        "    study.optimize(randomFOptuna, n_trials)\n",
        "    # result\n",
        "    print()\n",
        "    print('hyperparameter：', study.best_params)\n",
        "    print('AUC：', 1/study.best_value)\n",
        "    print()\n",
        "    return study.best_params['random_state']    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4Q-qw2-n6SZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8240ce7d-07e4-4dc7-fcd3-818c484cfe2f"
      },
      "source": [
        "randomFTrial(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-04 10:04:05,959]\u001b[0m A new study created in memory with name: no-name-7c7dea40-1b04-48d8-b0e1-baa56094bc94\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:04:11,310]\u001b[0m Trial 0 finished with value: 1.5053763440860215 and parameters: {'random_state': 616}. Best is trial 0 with value: 1.5053763440860215.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:04:16,624]\u001b[0m Trial 1 finished with value: 1.5849056603773586 and parameters: {'random_state': 1635}. Best is trial 0 with value: 1.5053763440860215.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:04:21,991]\u001b[0m Trial 2 finished with value: 1.5469613259668507 and parameters: {'random_state': 1476}. Best is trial 0 with value: 1.5053763440860215.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:04:27,296]\u001b[0m Trial 3 finished with value: 1.6310679611650485 and parameters: {'random_state': 1580}. Best is trial 0 with value: 1.5053763440860215.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:04:32,606]\u001b[0m Trial 4 finished with value: 1.5053763440860215 and parameters: {'random_state': 1889}. Best is trial 0 with value: 1.5053763440860215.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:04:37,901]\u001b[0m Trial 5 finished with value: 1.4659685863874348 and parameters: {'random_state': 74}. Best is trial 5 with value: 1.4659685863874348.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:04:43,296]\u001b[0m Trial 6 finished with value: 1.5849056603773586 and parameters: {'random_state': 852}. Best is trial 5 with value: 1.4659685863874348.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:04:48,656]\u001b[0m Trial 7 finished with value: 1.724845995893224 and parameters: {'random_state': 1947}. Best is trial 5 with value: 1.4659685863874348.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:04:53,942]\u001b[0m Trial 8 finished with value: 1.4285714285714286 and parameters: {'random_state': 89}. Best is trial 8 with value: 1.4285714285714286.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:04:59,264]\u001b[0m Trial 9 finished with value: 1.5849056603773586 and parameters: {'random_state': 1017}. Best is trial 8 with value: 1.4285714285714286.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:05:04,538]\u001b[0m Trial 10 finished with value: 1.5849056603773586 and parameters: {'random_state': 3}. Best is trial 8 with value: 1.4285714285714286.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:05:09,861]\u001b[0m Trial 11 finished with value: 1.5849056603773586 and parameters: {'random_state': 30}. Best is trial 8 with value: 1.4285714285714286.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:05:15,189]\u001b[0m Trial 12 finished with value: 1.4659685863874348 and parameters: {'random_state': 300}. Best is trial 8 with value: 1.4285714285714286.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:05:20,516]\u001b[0m Trial 13 finished with value: 1.541284403669725 and parameters: {'random_state': 333}. Best is trial 8 with value: 1.4285714285714286.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:05:25,860]\u001b[0m Trial 14 finished with value: 1.433447098976109 and parameters: {'random_state': 281}. Best is trial 8 with value: 1.4285714285714286.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:05:31,167]\u001b[0m Trial 15 finished with value: 1.4659685863874348 and parameters: {'random_state': 370}. Best is trial 8 with value: 1.4285714285714286.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:05:36,487]\u001b[0m Trial 16 finished with value: 1.5053763440860215 and parameters: {'random_state': 645}. Best is trial 8 with value: 1.4285714285714286.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:05:41,794]\u001b[0m Trial 17 finished with value: 1.541284403669725 and parameters: {'random_state': 1139}. Best is trial 8 with value: 1.4285714285714286.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:05:47,129]\u001b[0m Trial 18 finished with value: 1.3354531001589827 and parameters: {'random_state': 164}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:05:52,430]\u001b[0m Trial 19 finished with value: 1.5849056603773586 and parameters: {'random_state': 606}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:05:57,705]\u001b[0m Trial 20 finished with value: 1.5849056603773586 and parameters: {'random_state': 142}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:06:03,039]\u001b[0m Trial 21 finished with value: 1.5849056603773586 and parameters: {'random_state': 219}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:06:08,329]\u001b[0m Trial 22 finished with value: 1.433447098976109 and parameters: {'random_state': 532}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:06:13,676]\u001b[0m Trial 23 finished with value: 1.5849056603773586 and parameters: {'random_state': 507}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:06:18,991]\u001b[0m Trial 24 finished with value: 1.5469613259668507 and parameters: {'random_state': 462}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:06:24,323]\u001b[0m Trial 25 finished with value: 1.4659685863874348 and parameters: {'random_state': 829}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:06:29,634]\u001b[0m Trial 26 finished with value: 1.6247582205029016 and parameters: {'random_state': 6}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:06:34,958]\u001b[0m Trial 27 finished with value: 1.6247582205029016 and parameters: {'random_state': 808}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:06:40,235]\u001b[0m Trial 28 finished with value: 1.4659685863874348 and parameters: {'random_state': 146}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:06:45,544]\u001b[0m Trial 29 finished with value: 1.6247582205029016 and parameters: {'random_state': 263}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:06:50,837]\u001b[0m Trial 30 finished with value: 1.5849056603773586 and parameters: {'random_state': 708}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:06:56,144]\u001b[0m Trial 31 finished with value: 1.4659685863874348 and parameters: {'random_state': 473}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:07:01,436]\u001b[0m Trial 32 finished with value: 1.5469613259668507 and parameters: {'random_state': 385}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:07:06,762]\u001b[0m Trial 33 finished with value: 1.6247582205029016 and parameters: {'random_state': 169}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:07:12,063]\u001b[0m Trial 34 finished with value: 1.6733067729083666 and parameters: {'random_state': 1282}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:07:17,404]\u001b[0m Trial 35 finished with value: 1.4659685863874348 and parameters: {'random_state': 562}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:07:22,725]\u001b[0m Trial 36 finished with value: 1.6247582205029016 and parameters: {'random_state': 111}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:07:28,014]\u001b[0m Trial 37 finished with value: 1.724845995893224 and parameters: {'random_state': 265}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:07:33,282]\u001b[0m Trial 38 finished with value: 1.5053763440860215 and parameters: {'random_state': 424}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:07:38,615]\u001b[0m Trial 39 finished with value: 1.6247582205029016 and parameters: {'random_state': 737}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:07:43,919]\u001b[0m Trial 40 finished with value: 1.3354531001589827 and parameters: {'random_state': 966}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:07:49,227]\u001b[0m Trial 41 finished with value: 1.541284403669725 and parameters: {'random_state': 953}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:07:54,508]\u001b[0m Trial 42 finished with value: 1.717791411042945 and parameters: {'random_state': 1773}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:07:59,799]\u001b[0m Trial 43 finished with value: 1.5469613259668507 and parameters: {'random_state': 1195}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:08:05,078]\u001b[0m Trial 44 finished with value: 1.433447098976109 and parameters: {'random_state': 7}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:08:10,383]\u001b[0m Trial 45 finished with value: 1.6733067729083666 and parameters: {'random_state': 1470}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:08:15,677]\u001b[0m Trial 46 finished with value: 1.541284403669725 and parameters: {'random_state': 18}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:08:20,970]\u001b[0m Trial 47 finished with value: 1.6733067729083666 and parameters: {'random_state': 988}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:08:26,287]\u001b[0m Trial 48 finished with value: 1.541284403669725 and parameters: {'random_state': 40}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:08:31,583]\u001b[0m Trial 49 finished with value: 1.6247582205029016 and parameters: {'random_state': 91}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:08:36,876]\u001b[0m Trial 50 finished with value: 1.5849056603773586 and parameters: {'random_state': 207}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:08:42,194]\u001b[0m Trial 51 finished with value: 1.5849056603773586 and parameters: {'random_state': 342}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:08:47,495]\u001b[0m Trial 52 finished with value: 1.5849056603773586 and parameters: {'random_state': 287}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:08:52,782]\u001b[0m Trial 53 finished with value: 1.3636363636363635 and parameters: {'random_state': 204}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:08:58,084]\u001b[0m Trial 54 finished with value: 1.5849056603773586 and parameters: {'random_state': 69}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:09:03,373]\u001b[0m Trial 55 finished with value: 1.3680781758957654 and parameters: {'random_state': 211}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:09:08,684]\u001b[0m Trial 56 finished with value: 1.5849056603773586 and parameters: {'random_state': 200}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:09:14,013]\u001b[0m Trial 57 finished with value: 1.5053763440860215 and parameters: {'random_state': 109}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:09:19,357]\u001b[0m Trial 58 finished with value: 1.6310679611650485 and parameters: {'random_state': 1410}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:09:24,696]\u001b[0m Trial 59 finished with value: 1.5053763440860215 and parameters: {'random_state': 561}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:09:29,988]\u001b[0m Trial 60 finished with value: 1.541284403669725 and parameters: {'random_state': 362}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:09:35,263]\u001b[0m Trial 61 finished with value: 1.7721518987341773 and parameters: {'random_state': 12}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:09:40,571]\u001b[0m Trial 62 finished with value: 1.433447098976109 and parameters: {'random_state': 905}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:09:45,876]\u001b[0m Trial 63 finished with value: 1.7721518987341773 and parameters: {'random_state': 901}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:09:51,205]\u001b[0m Trial 64 finished with value: 1.7647058823529411 and parameters: {'random_state': 245}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:09:56,565]\u001b[0m Trial 65 finished with value: 1.4659685863874348 and parameters: {'random_state': 1104}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:10:01,908]\u001b[0m Trial 66 finished with value: 1.541284403669725 and parameters: {'random_state': 162}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:10:07,214]\u001b[0m Trial 67 finished with value: 1.5849056603773586 and parameters: {'random_state': 1638}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:10:12,543]\u001b[0m Trial 68 finished with value: 1.6310679611650485 and parameters: {'random_state': 1068}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:10:17,889]\u001b[0m Trial 69 finished with value: 1.6310679611650485 and parameters: {'random_state': 417}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:10:23,230]\u001b[0m Trial 70 finished with value: 1.3354531001589827 and parameters: {'random_state': 324}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:10:28,597]\u001b[0m Trial 71 finished with value: 1.4659685863874348 and parameters: {'random_state': 1211}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:10:33,962]\u001b[0m Trial 72 finished with value: 1.8834080717488788 and parameters: {'random_state': 309}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:10:39,321]\u001b[0m Trial 73 finished with value: 1.5 and parameters: {'random_state': 194}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:10:44,660]\u001b[0m Trial 74 finished with value: 1.541284403669725 and parameters: {'random_state': 122}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:10:49,954]\u001b[0m Trial 75 finished with value: 1.6310679611650485 and parameters: {'random_state': 470}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:10:55,282]\u001b[0m Trial 76 finished with value: 1.5849056603773586 and parameters: {'random_state': 756}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:11:00,578]\u001b[0m Trial 77 finished with value: 1.6733067729083666 and parameters: {'random_state': 647}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:11:05,887]\u001b[0m Trial 78 finished with value: 1.8918918918918919 and parameters: {'random_state': 254}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:11:11,195]\u001b[0m Trial 79 finished with value: 1.5849056603773586 and parameters: {'random_state': 528}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:11:16,515]\u001b[0m Trial 80 finished with value: 1.541284403669725 and parameters: {'random_state': 933}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:11:21,829]\u001b[0m Trial 81 finished with value: 1.6310679611650485 and parameters: {'random_state': 406}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:11:27,158]\u001b[0m Trial 82 finished with value: 1.7721518987341773 and parameters: {'random_state': 51}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:11:32,470]\u001b[0m Trial 83 finished with value: 1.8918918918918919 and parameters: {'random_state': 866}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:11:37,787]\u001b[0m Trial 84 finished with value: 1.5849056603773586 and parameters: {'random_state': 319}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:11:43,104]\u001b[0m Trial 85 finished with value: 1.5849056603773586 and parameters: {'random_state': 3}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:11:48,457]\u001b[0m Trial 86 finished with value: 1.3354531001589827 and parameters: {'random_state': 164}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:11:53,759]\u001b[0m Trial 87 finished with value: 1.4659685863874348 and parameters: {'random_state': 174}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:11:59,082]\u001b[0m Trial 88 finished with value: 1.3976705490848584 and parameters: {'random_state': 1031}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:12:04,399]\u001b[0m Trial 89 finished with value: 1.541284403669725 and parameters: {'random_state': 1188}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:12:09,693]\u001b[0m Trial 90 finished with value: 1.724845995893224 and parameters: {'random_state': 73}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:12:15,026]\u001b[0m Trial 91 finished with value: 1.4659685863874348 and parameters: {'random_state': 985}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:12:20,332]\u001b[0m Trial 92 finished with value: 1.541284403669725 and parameters: {'random_state': 231}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:12:25,655]\u001b[0m Trial 93 finished with value: 1.5107913669064745 and parameters: {'random_state': 1076}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:12:30,958]\u001b[0m Trial 94 finished with value: 1.541284403669725 and parameters: {'random_state': 124}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:12:36,276]\u001b[0m Trial 95 finished with value: 1.4659685863874348 and parameters: {'random_state': 1313}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:12:41,577]\u001b[0m Trial 96 finished with value: 1.68 and parameters: {'random_state': 147}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:12:46,926]\u001b[0m Trial 97 finished with value: 1.6733067729083666 and parameters: {'random_state': 1049}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:12:52,237]\u001b[0m Trial 98 finished with value: 1.5469613259668507 and parameters: {'random_state': 364}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:12:57,559]\u001b[0m Trial 99 finished with value: 1.433447098976109 and parameters: {'random_state': 294}. Best is trial 18 with value: 1.3354531001589827.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "hyperparameter： {'random_state': 164}\n",
            "AUC： 0.7488095238095237\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "164"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQjSaZD6DiMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10adf181-6210-4ce7-ea46-5ad6df49edce"
      },
      "source": [
        "# This random_state value is one example of hyperparameter optimization. There are other values that yield a similar AUC value.\n",
        "randomF(164)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with Random Forest\n",
            "\n",
            "Sample size of all dataset: 43\n",
            "Sample size of training data: 42     Explanatory variables: (42, 60)   Target value: (42,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 60)   Target value: (1,)\n",
            "\n",
            "AUC: 0.74881   Accuracy: 0.81395   R2: 0.18095\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             8             1\n",
            "Predict False            7            27\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.7488095238095237, 0.813953488372093, 0.8888888888888888,\n",
              "       0.5333333333333333, 0.6666666666666666, 0.9642857142857143,\n",
              "       list([[8, 1], [7, 27]]), 0.1809523809523811], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJD4d2FnG3G-"
      },
      "source": [
        "## 7) XGBoost ; AUC 0.826"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9AwzxeuiBdD"
      },
      "source": [
        "def xgboost(eta):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "    import xgboost as xgb\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score\n",
        "\n",
        "    # Rounding of fractional point\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p    \n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    # Predicted value\n",
        "    round = []\n",
        "    pred = []\n",
        "    pairs = []\n",
        "    \n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "\n",
        "\n",
        "    # Hypter-parameter settings\n",
        "    params = {\n",
        "        'objective' : 'binary:logistic',\n",
        "        'silent' : 0,\n",
        "        'eta' : eta,\n",
        "        'random_state' : 71,\n",
        "        'max_depth' : 5,\n",
        "        'eval_metric' : 'logloss'\n",
        "    }\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        # transform data structure for XGBoost\n",
        "        d_train = xgb.DMatrix(x_train, label=t_train)\n",
        "        d_test = xgb.DMatrix(x_test, label=t_test)\n",
        "        # training\n",
        "        model = xgb.train(params, d_train)\n",
        "        result = model.predict(d_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "\n",
        "        # Category of prediction\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "\n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/program/data/cstatdata.csv', index=False)\n",
        "\n",
        "    # Coefficient of Determination\n",
        "    r2 = r2_score(t, pred)\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)    \n",
        "\n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat = [[TP, FP], [FN, TN]]\n",
        "\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "\n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, [[TP, FP], [FN, TN]], r2])\n",
        "\n",
        "    # Output　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. Confusion Matrix, 8. R^2 in LOO)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation with XGBoost')\n",
        "    print('')\n",
        "    print('Sample size of all dataset: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('Sample size of training data: ' + str(len(x_train)) + '     Explanatory variables: ' + str(x_train.shape) + '   Target value: ' + str(t_train.shape))\n",
        "    print('Sample size of test data: ' + str(len(x_test)) + '     Explanatory variables: ' + str(x_test.shape) + '   Target value: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO')\n",
        "    print('')\n",
        "\n",
        "\n",
        "    return res\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hMT5l1gnEnH"
      },
      "source": [
        "### Optimization with Optuna"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXLL3vROkSN_"
      },
      "source": [
        "def xgboostOptuna(trial):\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "    import xgboost as xgb\n",
        "\n",
        "    import optuna\n",
        "\n",
        "    # Statistical functions\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "\n",
        "    eta = trial.suggest_uniform('eta', 0, 1)\n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "\n",
        "    round = []\n",
        "    pred = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "\n",
        "\n",
        "    # Hypter-parameter settings\n",
        "    params = {\n",
        "        'objective' : 'binary:logistic',\n",
        "        'silent' : 0,\n",
        "        'eta' : eta,\n",
        "        'random_state' : 71,\n",
        "        'max_depth' : 5,\n",
        "        'eval_metric' : 'logloss'\n",
        "    }\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        # transform data structure for XGBoost\n",
        "        d_train = xgb.DMatrix(x_train, label=t_train)\n",
        "        d_test = xgb.DMatrix(x_test, label=t_test)\n",
        "        # training\n",
        "        model = xgb.train(params, d_train)\n",
        "        result = model.predict(d_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    res = auc\n",
        "    # minimize 1/AUC\n",
        "    return 1/res\n",
        "\n",
        "\n",
        "def xgboostTrial(n_trials):\n",
        "    import optuna\n",
        "    study = optuna.create_study()\n",
        "    study.optimize(xgboostOptuna, n_trials)\n",
        "\n",
        "    # result\n",
        "    print()\n",
        "    print('hyperparameter：', study.best_params)\n",
        "    print('AUC：', 1/study.best_value) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQMdDN9cGX91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab101d1-e9bc-416d-c7a3-ab5fb90035b7"
      },
      "source": [
        "xgboostTrial(100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2020-12-04 10:13:49,475]\u001b[0m A new study created in memory with name: no-name-f9521243-b530-410b-beac-e0dd68667635\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:49,774]\u001b[0m Trial 0 finished with value: 1.418918918918919 and parameters: {'eta': 0.9595872718886741}. Best is trial 0 with value: 1.418918918918919.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:50,090]\u001b[0m Trial 1 finished with value: 1.4334470989761092 and parameters: {'eta': 0.02696521703285637}. Best is trial 0 with value: 1.418918918918919.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:50,381]\u001b[0m Trial 2 finished with value: 1.4 and parameters: {'eta': 0.7271233953305385}. Best is trial 2 with value: 1.4.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:50,712]\u001b[0m Trial 3 finished with value: 1.4 and parameters: {'eta': 0.0742643336000598}. Best is trial 2 with value: 1.4.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:51,025]\u001b[0m Trial 4 finished with value: 1.238938053097345 and parameters: {'eta': 0.2531268354960651}. Best is trial 4 with value: 1.238938053097345.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:51,319]\u001b[0m Trial 5 finished with value: 1.516245487364621 and parameters: {'eta': 0.7566283491683932}. Best is trial 4 with value: 1.238938053097345.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:51,647]\u001b[0m Trial 6 finished with value: 1.3815789473684208 and parameters: {'eta': 0.08236338606377946}. Best is trial 4 with value: 1.238938053097345.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:51,961]\u001b[0m Trial 7 finished with value: 1.2962962962962963 and parameters: {'eta': 0.40851783845849066}. Best is trial 4 with value: 1.238938053097345.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:52,251]\u001b[0m Trial 8 finished with value: 1.3770491803278688 and parameters: {'eta': 0.7225752344262977}. Best is trial 4 with value: 1.238938053097345.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:52,568]\u001b[0m Trial 9 finished with value: 1.3084112149532712 and parameters: {'eta': 0.44630170234672595}. Best is trial 4 with value: 1.238938053097345.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:52,881]\u001b[0m Trial 10 finished with value: 1.2244897959183674 and parameters: {'eta': 0.2719851864509955}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:53,199]\u001b[0m Trial 11 finished with value: 1.25 and parameters: {'eta': 0.26410068050928476}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:53,532]\u001b[0m Trial 12 finished with value: 1.2426035502958581 and parameters: {'eta': 0.2496236263694061}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:53,846]\u001b[0m Trial 13 finished with value: 1.238938053097345 and parameters: {'eta': 0.25341482062354953}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:54,150]\u001b[0m Trial 14 finished with value: 1.4583333333333333 and parameters: {'eta': 0.5591835052285228}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:54,467]\u001b[0m Trial 15 finished with value: 1.2244897959183674 and parameters: {'eta': 0.17756139817880945}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:54,801]\u001b[0m Trial 16 finished with value: 1.2612612612612613 and parameters: {'eta': 0.14326239241340227}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:55,115]\u001b[0m Trial 17 finished with value: 1.3124999999999998 and parameters: {'eta': 0.3651209198613434}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:55,425]\u001b[0m Trial 18 finished with value: 1.5 and parameters: {'eta': 0.568877122815783}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:55,757]\u001b[0m Trial 19 finished with value: 1.25748502994012 and parameters: {'eta': 0.16058455149434414}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:56,077]\u001b[0m Trial 20 finished with value: 1.4893617021276597 and parameters: {'eta': 0.0026207415513866406}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:56,393]\u001b[0m Trial 21 finished with value: 1.242603550295858 and parameters: {'eta': 0.3127872734447036}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:56,717]\u001b[0m Trial 22 finished with value: 1.3003095975232197 and parameters: {'eta': 0.22377610259761513}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:57,034]\u001b[0m Trial 23 finished with value: 1.2688821752265862 and parameters: {'eta': 0.1555060214645314}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:57,355]\u001b[0m Trial 24 finished with value: 1.2280701754385965 and parameters: {'eta': 0.33129177016701045}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:57,679]\u001b[0m Trial 25 finished with value: 1.3375796178343948 and parameters: {'eta': 0.36203702159121065}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:57,984]\u001b[0m Trial 26 finished with value: 1.4046822742474916 and parameters: {'eta': 0.5107029954641861}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:58,325]\u001b[0m Trial 27 finished with value: 1.2244897959183674 and parameters: {'eta': 0.32749028348430576}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:58,645]\u001b[0m Trial 28 finished with value: 1.35048231511254 and parameters: {'eta': 0.43060036360349235}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:58,971]\u001b[0m Trial 29 finished with value: 1.2650602409638554 and parameters: {'eta': 0.19121921871427267}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:59,290]\u001b[0m Trial 30 finished with value: 1.3249211356466877 and parameters: {'eta': 0.10243382075614571}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:59,616]\u001b[0m Trial 31 finished with value: 1.253731343283582 and parameters: {'eta': 0.3188438596340277}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:13:59,931]\u001b[0m Trial 32 finished with value: 1.268882175226586 and parameters: {'eta': 0.32377129365869256}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:00,245]\u001b[0m Trial 33 finished with value: 1.3418530351437699 and parameters: {'eta': 0.45068935493312884}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:00,560]\u001b[0m Trial 34 finished with value: 1.3124999999999998 and parameters: {'eta': 0.35856981074110933}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:00,885]\u001b[0m Trial 35 finished with value: 1.4 and parameters: {'eta': 0.05975474520778451}. Best is trial 10 with value: 1.2244897959183674.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:01,203]\u001b[0m Trial 36 finished with value: 1.2244897959183672 and parameters: {'eta': 0.2080034361308759}. Best is trial 36 with value: 1.2244897959183672.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:01,516]\u001b[0m Trial 37 finished with value: 1.242603550295858 and parameters: {'eta': 0.20077278715090485}. Best is trial 36 with value: 1.2244897959183672.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:01,850]\u001b[0m Trial 38 finished with value: 1.3291139240506329 and parameters: {'eta': 0.1175325618857564}. Best is trial 36 with value: 1.2244897959183672.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:02,169]\u001b[0m Trial 39 finished with value: 1.4141414141414144 and parameters: {'eta': 0.028037561541282563}. Best is trial 36 with value: 1.2244897959183672.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:02,456]\u001b[0m Trial 40 finished with value: 1.4141414141414141 and parameters: {'eta': 0.9635661360536514}. Best is trial 36 with value: 1.2244897959183672.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:02,784]\u001b[0m Trial 41 finished with value: 1.2727272727272727 and parameters: {'eta': 0.2951131032329715}. Best is trial 36 with value: 1.2244897959183672.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:03,100]\u001b[0m Trial 42 finished with value: 1.2209302325581395 and parameters: {'eta': 0.20716255051210505}. Best is trial 42 with value: 1.2209302325581395.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:03,418]\u001b[0m Trial 43 finished with value: 1.2462908011869438 and parameters: {'eta': 0.19449901830994268}. Best is trial 42 with value: 1.2209302325581395.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:03,741]\u001b[0m Trial 44 finished with value: 1.2426035502958581 and parameters: {'eta': 0.24912665957956814}. Best is trial 42 with value: 1.2209302325581395.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:04,064]\u001b[0m Trial 45 finished with value: 1.4046822742474914 and parameters: {'eta': 0.06531158815865853}. Best is trial 42 with value: 1.2209302325581395.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:04,382]\u001b[0m Trial 46 finished with value: 1.2462908011869436 and parameters: {'eta': 0.2797031210999084}. Best is trial 42 with value: 1.2209302325581395.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:04,703]\u001b[0m Trial 47 finished with value: 1.3249211356466877 and parameters: {'eta': 0.404685069992757}. Best is trial 42 with value: 1.2209302325581395.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:05,023]\u001b[0m Trial 48 finished with value: 1.2727272727272727 and parameters: {'eta': 0.13388175411683934}. Best is trial 42 with value: 1.2209302325581395.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:05,337]\u001b[0m Trial 49 finished with value: 1.2103746397694524 and parameters: {'eta': 0.2070208869460045}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:05,668]\u001b[0m Trial 50 finished with value: 1.2688821752265862 and parameters: {'eta': 0.21280022461959486}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:05,982]\u001b[0m Trial 51 finished with value: 1.2244897959183674 and parameters: {'eta': 0.1775302649114756}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:06,307]\u001b[0m Trial 52 finished with value: 1.2280701754385965 and parameters: {'eta': 0.17012108430475303}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:06,627]\u001b[0m Trial 53 finished with value: 1.346153846153846 and parameters: {'eta': 0.09903685197728314}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:06,957]\u001b[0m Trial 54 finished with value: 1.253731343283582 and parameters: {'eta': 0.2383970314882171}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:07,272]\u001b[0m Trial 55 finished with value: 1.3999999999999997 and parameters: {'eta': 0.03564212961112079}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:07,591]\u001b[0m Trial 56 finished with value: 1.2650602409638554 and parameters: {'eta': 0.1593008050652604}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:07,915]\u001b[0m Trial 57 finished with value: 1.238938053097345 and parameters: {'eta': 0.26493144461963297}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:08,239]\u001b[0m Trial 58 finished with value: 1.308411214953271 and parameters: {'eta': 0.2254007481404091}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:08,548]\u001b[0m Trial 59 finished with value: 1.390728476821192 and parameters: {'eta': 0.6767777168922127}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:08,864]\u001b[0m Trial 60 finished with value: 1.3815789473684208 and parameters: {'eta': 0.8653092216835563}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:09,179]\u001b[0m Trial 61 finished with value: 1.25 and parameters: {'eta': 0.2835549808061853}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:09,503]\u001b[0m Trial 62 finished with value: 1.238938053097345 and parameters: {'eta': 0.18062401096446973}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:09,829]\u001b[0m Trial 63 finished with value: 1.2765957446808511 and parameters: {'eta': 0.12674850444372315}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:10,144]\u001b[0m Trial 64 finished with value: 1.308411214953271 and parameters: {'eta': 0.22492690919510133}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:10,454]\u001b[0m Trial 65 finished with value: 1.3124999999999998 and parameters: {'eta': 0.39439711178062375}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:10,775]\u001b[0m Trial 66 finished with value: 1.3725490196078431 and parameters: {'eta': 0.08594493033360431}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:11,089]\u001b[0m Trial 67 finished with value: 1.2962962962962963 and parameters: {'eta': 0.35192884586235196}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:11,410]\u001b[0m Trial 68 finished with value: 1.2688821752265862 and parameters: {'eta': 0.2891368366558986}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:11,727]\u001b[0m Trial 69 finished with value: 1.2352941176470589 and parameters: {'eta': 0.1488104019731365}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:12,054]\u001b[0m Trial 70 finished with value: 1.4736842105263157 and parameters: {'eta': 0.0031184639171686623}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:12,367]\u001b[0m Trial 71 finished with value: 1.2688821752265862 and parameters: {'eta': 0.3221138034390973}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:12,688]\u001b[0m Trial 72 finished with value: 1.242603550295858 and parameters: {'eta': 0.16504182018452299}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:13,018]\u001b[0m Trial 73 finished with value: 1.2426035502958581 and parameters: {'eta': 0.19425264754458504}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:13,343]\u001b[0m Trial 74 finished with value: 1.2244897959183674 and parameters: {'eta': 0.1772475874737836}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:13,660]\u001b[0m Trial 75 finished with value: 1.238938053097345 and parameters: {'eta': 0.2533319939701733}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:13,992]\u001b[0m Trial 76 finished with value: 1.3291139240506327 and parameters: {'eta': 0.11892186947102079}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:14,327]\u001b[0m Trial 77 finished with value: 1.2209302325581395 and parameters: {'eta': 0.2072108764068268}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:14,640]\u001b[0m Trial 78 finished with value: 1.2103746397694524 and parameters: {'eta': 0.20622976660623452}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:14,966]\u001b[0m Trial 79 finished with value: 1.2173913043478262 and parameters: {'eta': 0.30445427205656417}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:15,272]\u001b[0m Trial 80 finished with value: 1.320754716981132 and parameters: {'eta': 0.46290282859205445}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:15,589]\u001b[0m Trial 81 finished with value: 1.25 and parameters: {'eta': 0.21162496787183355}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:15,913]\u001b[0m Trial 82 finished with value: 1.238938053097345 and parameters: {'eta': 0.30237776801373234}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:16,228]\u001b[0m Trial 83 finished with value: 1.253731343283582 and parameters: {'eta': 0.23909767141650365}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:16,556]\u001b[0m Trial 84 finished with value: 1.2462908011869438 and parameters: {'eta': 0.19268319125171754}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:16,878]\u001b[0m Trial 85 finished with value: 1.25 and parameters: {'eta': 0.2635647558143603}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:17,201]\u001b[0m Trial 86 finished with value: 1.2727272727272727 and parameters: {'eta': 0.13719905947520158}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:17,513]\u001b[0m Trial 87 finished with value: 1.2883435582822085 and parameters: {'eta': 0.34224387380786336}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:17,832]\u001b[0m Trial 88 finished with value: 1.3124999999999998 and parameters: {'eta': 0.10471936733118013}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:18,163]\u001b[0m Trial 89 finished with value: 1.390728476821192 and parameters: {'eta': 0.052221175835450606}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:18,484]\u001b[0m Trial 90 finished with value: 1.2316715542521994 and parameters: {'eta': 0.2685223591547275}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:18,799]\u001b[0m Trial 91 finished with value: 1.2650602409638554 and parameters: {'eta': 0.22134082309039133}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:19,151]\u001b[0m Trial 92 finished with value: 1.2727272727272727 and parameters: {'eta': 0.3785239990455615}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:19,467]\u001b[0m Trial 93 finished with value: 1.25 and parameters: {'eta': 0.239919948563623}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:19,784]\u001b[0m Trial 94 finished with value: 1.2280701754385965 and parameters: {'eta': 0.17034906502198588}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:20,108]\u001b[0m Trial 95 finished with value: 1.2612612612612613 and parameters: {'eta': 0.3094209492108032}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:20,427]\u001b[0m Trial 96 finished with value: 1.2103746397694524 and parameters: {'eta': 0.206729896051697}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:20,746]\u001b[0m Trial 97 finished with value: 1.238938053097345 and parameters: {'eta': 0.198540462915811}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:21,073]\u001b[0m Trial 98 finished with value: 1.2574850299401197 and parameters: {'eta': 0.28225089787427815}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n",
            "\u001b[32m[I 2020-12-04 10:14:21,395]\u001b[0m Trial 99 finished with value: 1.2537313432835822 and parameters: {'eta': 0.14642252292242902}. Best is trial 49 with value: 1.2103746397694524.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "hyperparameter： {'eta': 0.2070208869460045}\n",
            "AUC： 0.8261904761904763\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZM2neJGHPIQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf1c442-37bd-4a89-bdd1-c72dcbe3cd53"
      },
      "source": [
        "# This eta value is one example of hyperparameter optimization. There are other values that yield a similar AUC value.\n",
        "xgboost(0.2070208869460045)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "■ Leave-One-Out Cross Validation with XGBoost\n",
            "\n",
            "Sample size of all dataset: 43\n",
            "Sample size of training data: 42     Explanatory variables: (42, 60)   Target value: (42,)\n",
            "Sample size of test data: 1     Explanatory variables: (1, 60)   Target value: (1,)\n",
            "\n",
            "AUC: 0.82619   Accuracy: 0.69767   R2: 0.24438\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True             9             7\n",
            "Predict False            6            21\n",
            "\n",
            "Output: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. Confution matrix 8. R^2 in LOO\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.8261904761904763, 0.6976744186046512, 0.5625, 0.6,\n",
              "       0.5806451612903226, 0.75, list([[9, 7], [6, 21]]),\n",
              "       0.24438171190176772], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6mA6S6UG3pP"
      },
      "source": [
        "## 8) Naive Bayes  ACU 0.548"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLIP310lG3LM"
      },
      "source": [
        "def naiveBayes():\n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.naive_bayes import GaussianNB\n",
        "    from sklearn.model_selection import LeaveOneOut\n",
        "\n",
        "    # 統計処理関数\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    from sklearn.metrics import r2_score\n",
        "\n",
        "    # 端数処理\n",
        "    import math\n",
        "    def my_round(val, digit=0):\n",
        "        p = 10 ** digit\n",
        "        return (val * p * 2 + 1) // 2 / p\n",
        "\n",
        "\n",
        "    x = []\n",
        "    t = []\n",
        "    # 予測値\n",
        "    pred = []\n",
        "    round = []\n",
        "    pairs = []\n",
        "\n",
        "    for row in data:\n",
        "        u = []\n",
        "        t.append(int(row[-1]))\n",
        "        for i in range(0, len(row)-1):\n",
        "            u.append(float(row[i]))\n",
        "        x.append(u)\n",
        "\n",
        "    x = np.array(x)\n",
        "    t = np.array(t)\n",
        "\n",
        "\n",
        "    loo = LeaveOneOut()\n",
        "    entire_count = loo.get_n_splits(x)\n",
        "    nb = GaussianNB()\n",
        "\n",
        "    for train_index, test_index in loo.split(x):\n",
        "        x_train, x_test = x[train_index], x[test_index]\n",
        "        t_train, t_test = t[train_index], t[test_index]\n",
        "        nb.fit(x_train, t_train)\n",
        "        result = nb.predict(x_test)\n",
        "        pred.append(result[0])\n",
        "\n",
        "        # 予測値のカテゴリー\n",
        "        if (result[0]<0.5):\n",
        "            round.append(int(0))\n",
        "        else:\n",
        "            round.append(int(1)) \n",
        "\n",
        "    for i in range(len(pred)):\n",
        "        pairs.append([pred[i], t[i]])\n",
        "\n",
        "    output = pd.DataFrame(pairs)\n",
        "    # output.to_csv('drive/My Drive/Kataoka/data/MaxGDout.csv', index=False)\n",
        "\n",
        "    # 決定係数\n",
        "    r2 = r2_score(t, pred)\n",
        "    # AUC\n",
        "    auc = roc_auc_score(t, pred)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "    TN = 0\n",
        "\n",
        "    for i in range(len(round)):\n",
        "        if (round[i]==1) & (t[i]==1):\n",
        "            TP += 1\n",
        "        elif (round[i]==1) & (t[i]==0):\n",
        "            FP += 1\n",
        "        elif (round[i]==0) & (t[i]==1):\n",
        "            FN += 1\n",
        "        elif (round[i]==0) & (t[i]==0):\n",
        "            TN += 1\n",
        "\n",
        "    confmat =  [[TP, FP], [FN, TN]]\n",
        "\n",
        "    acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "    \n",
        "    if TP + FP != 0:\n",
        "        prec = TP/(TP+FP)\n",
        "    elif TP + FP == 0:\n",
        "        prec = 'N/A'\n",
        "    if TP + FN != 0:\n",
        "        rec = TP/(TP+FN)\n",
        "    elif TP + FP ==0:\n",
        "        rec = 'N/A'\n",
        "    if TN + FP != 0:\n",
        "        spec = TN/(TN + FP)\n",
        "    elif TN + FP == 0:\n",
        "        spec = 'N/A'\n",
        "    if TP + FP/2 + FN/2 != 0:\n",
        "        f1 = TP/(TP + FP/2 + FN/2)\n",
        "    elif TP + FP/2 + FN/2 == 0:\n",
        "        f1 = 'N/A'\n",
        "\n",
        "    res = np.array([auc, acc, prec, rec, f1, spec, [[TP, FP], [FN, TN]], r2])\n",
        "\n",
        "    # 出力　: ( 1. AUC, 2, Accuracy, 3. Precision 4. Recall 5. f1-score 6. Specificity, 7. 混合行列, 8. LOOにおける決定係数)\n",
        "\n",
        "    print('■ Leave-One-Out Cross Validation を用いた Naive Bayes による2値分類の検定結果')\n",
        "    print('')\n",
        "    print('全データのサンプル数: ' + str(len(x_train) + len(x_test)) )  \n",
        "    print('学習データのサンプル数: ' + str(len(x_train)) + '     説明変数: ' + str(x_train.shape) + '   目的変数: ' + str(t_train.shape))\n",
        "    print('検証データのサンプル数: ' + str(len(x_test)) + '     説明変数: ' + str(x_test.shape) + '   目的変数: ' + str(t_test.shape))\n",
        "    print('')\n",
        "    print('AUC: ' + str(my_round(auc, 5)) + '   Accuracy: ' + str(my_round(acc,5)) + '   R2: ' + str(my_round(r2,5)))    \n",
        "    print('')\n",
        "    print(pd.DataFrame(np.array(confmat), index=['Predict True', 'Predict False'], columns=['Actual True', 'Actual False']))\n",
        "    print('')\n",
        "    print('出力の内容: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. 混合行列 8. LOOにおける決定係数')\n",
        "    print('')\n",
        "\n",
        "\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Zt6mGljIG5o",
        "outputId": "b0d23a08-3877-4c65-ce6d-0f4bb566327d"
      },
      "source": [
        "naiveBayes()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "■ Leave-One-Out Cross Validation を用いた Naive Bayes による2値分類の検定結果\n",
            "\n",
            "全データのサンプル数: 43\n",
            "学習データのサンプル数: 42     説明変数: (42, 60)   目的変数: (42,)\n",
            "検証データのサンプル数: 1     説明変数: (1, 60)   目的変数: (1,)\n",
            "\n",
            "AUC: 0.54762   Accuracy: 0.51163   R2: -1.15\n",
            "\n",
            "               Actual True  Actual False\n",
            "Predict True            10            16\n",
            "Predict False            5            12\n",
            "\n",
            "出力の内容: 1. AUC 2. Accuracy 3. Precision 4. Recall 5. f1-score 6. Specificity 7. 混合行列 8. LOOにおける決定係数\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:101: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.5476190476190477, 0.5116279069767442, 0.38461538461538464,\n",
              "       0.6666666666666666, 0.4878048780487805, 0.42857142857142855,\n",
              "       list([[10, 16], [5, 12]]), -1.15], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLwrb35HG5kG"
      },
      "source": [
        "## 9) Symbolic Regression ; AUC 0.774"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbRQDssWK39X"
      },
      "source": [
        "#### See Leave-One-Out CV with renaldata by SR via GP.pdf file for the calculation processes of LOO with Symbolic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YGp_tZbra4o"
      },
      "source": [
        "- Results of Leave-One-Out CV with SR via GP\n",
        "- ROC-AUC 0.774\n",
        "- Accuracy 0.767\n",
        "- Precision 0.727\n",
        "- Recall 0.533\n",
        "- Sepcificity 0.893\n",
        "- F1-measure 0.615\n",
        "- C-statistics 0.774"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbqSJ3CbOsFl"
      },
      "source": [
        "                 Actual True   Actual False\n",
        "Predicted True      8              3\n",
        "Predicted False      7             25 "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}